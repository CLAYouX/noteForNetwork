[TOC]

## 一、基础篇

### 1.1 TCP/IP 网络模型

对于同⼀台设备上的进程间通信，有很多种⽅式，⽐如有管道、消息队列、共享内存、信号等⽅式，⽽对于不同设
备上的进程间通信，就需要⽹络通信，⽽设备是多样性的，所以要兼容多种多样的设备，就协商出了⼀套 **通⽤的⽹络协议**。

这个⽹络协议是分层的，每⼀层都有各⾃的作⽤和职责。

#### 应用层

应⽤层只需要专注于为⽤户提供应⽤功能，不⽤去关⼼数据是如何传输的。

应⽤层是⼯作在操作系统中的 **⽤户态**，传输层及以下则⼯作在内核态。

#### 传输层

应⽤层的数据包会传给传输层，**传输层（Transport Layer）** 是为应⽤层提供⽹络⽀持的。

在传输层会有两个传输协议，分别是 **TCP** 和 **UDP**。

应⽤需要传输的数据可能会⾮常⼤，如果直接传输就不好控制，因此当传输层的数据包⼤⼩超过 **MSS（TCP 最⼤报⽂段⻓度）** ，就要将数据包分块，这样即使中途有⼀个分块丢失或损坏了，只需要重新这⼀个分块，⽽不⽤重新发送整个数据包。在 TCP 协议中，我们把每个分块称为⼀个 **TCP 段（TCP Segment）**，如下图所示：

![TCP分段.PNG](https://i.loli.net/2021/08/08/IS6iJurz5bw1Y2f.png)

当设备作为接收⽅时，传输层则要负责把数据包传给应⽤，但是⼀台设备上可能会有很多应⽤在接收或者传输数据，因此需要⽤⼀个编号将应⽤区分开来，这个编号就是 **端⼝**。

浏览器（客户端）中的每个标签栏都是⼀个 **独⽴的进程**，操作系统会为这些进程分配临时的端⼝号。

#### 网络层

我们不希望传输层协议处理太多的事情，只需要服务好应⽤即可，让其作为应⽤间数据传输的媒介，帮助实现应⽤到应⽤的通信，⽽实际的传输功能就交给下⼀层，也就是 **⽹络层（Internet Layer）**。

网络层最常使用的是 **IP协议（Internet Protocol）**，IP 协议会将传输层的报⽂作为数据部分，再加上 IP 包头组装成 IP 报⽂，如果 IP 报⽂⼤⼩超过 **最大传输单元MTU**（以太⽹中⼀般为 1500 字节），就会再次进⾏ **分⽚**，得到⼀个即将发送到⽹络的 IP 报⽂。

![IP报文.PNG](https://i.loli.net/2021/08/08/lPdOjzaUb5VNvTW.png)

⽹络层负责 **将数据从⼀个设备传输到另⼀个设备**。因此，⽹络层需要有区分设备的编号。

⼀般⽤ **IP 地址** 给设备进⾏编号，对于 IPv4 协议， IP 地址共 32 位，分成了四段，每段是 8 位。 IP 地址可以分成两种意义：

- 一个是 **网络号**，负责标识该 IP 地址属于哪个子网；
- 一个是 **主机号**，负责标识同一子网下的不同主机；

这需要配合 **子网掩码** 才能算出 IP 地址 的⽹络号和主机号。在寻址的过程中，先匹配到相同的⽹络号，再去找对应的主机。

除了寻址能⼒， IP 协议还有另⼀个重要的能⼒就是 **路由**。实际场景中，两台设备并不是⽤⼀条⽹线连接起来的，⽽是通过很多⽹关、路由器、交换机等众多⽹络设备连接起来的，那么就会形成很多条⽹络的路径。因此，当数据包到达⼀个⽹络节点，就需要通过算法决定下⼀步⾛哪条路径。

所以，**IP 协议的寻址作用是告诉我们去往下⼀个⽬的地该朝哪个⽅向⾛，路由则是根据「下⼀个⽬的地」选择路径**。寻址更像在导航，路由更像在操作⽅向盘。

#### 数据链路层

网络中由一个专⻔的层来标识⽹络中的设备，让数据在⼀个链路中传输，这就是 **数据链路层（Data Link Layer）**，它主要为⽹络层提供链路级别传输的服务。

每⼀台设备的⽹卡都会有⼀个 MAC 地址，⽤来唯⼀标识设备。路由器计算出了下⼀个⽬的地 IP 地址，再通过 **ARP 协议** 找到该⽬的地的 MAC 地址，这样就知道这个 IP 地址是哪个设备的了。

#### 物理层

当数据要从设备发送到⽹络时，需要把数据包转换成电信号，让其可以在物理介质中传输，这⼀层就是 **物理层（Physical Layer）**，它主要是为数据链路层提供⼆进制传输的服务。

## 二、HTTP篇

### 2.1 HTTP基本概念

HTTP 是 **超⽂本传输协议**。

HTTP 是⼀个⽤在计算机世界⾥的协议。它使⽤计算机能够理解的语⾔确⽴了⼀种计算机之间交流通信的规范（**两个以上的参与者**），以及相关的各种控制和错误处理⽅式（**⾏为约定和规范**）。

HTTP 是⼀个在计算机世界⾥专⻔⽤来在 **两点之间传输数据** 的约定和规范。

HTTP 是⼀个 **在计算机世界⾥专⻔在「两点」之间「传输」⽂字、图⽚、⾳频、视频等「超⽂本」数据的「约定和规范」**。

#### HTTP常见状态码

![HTTP状态码.PNG](https://i.loli.net/2021/08/08/ZtTljcFDWEIfRsk.png)

### 2.2 HTTP特性

#### HTTP 1.1 优点

HTTP 最凸出的优点是「简单、灵活和易于扩展、应⽤⼴泛和跨平台」。

#### 缺点

HTTP 协议⾥有优缺点⼀体的双刃剑，分别是**「⽆状态、明⽂传输」**，同时还有⼀⼤缺点**「不安全」**。

##### 无状态——双刃剑

⽆状态的好处，因为服务器不会去记忆 HTTP 的状态，所以 **不需要额外的资源来记录状态信息**，这能减轻服务器的负担，能够把更多的 CPU 和内存⽤来对外提供服务。

⽆状态的坏处，既然服务器没有记忆能⼒，它在完成有关联性的操作时会⾮常麻烦。例如登录->添加购物⻋->下单->结算->⽀付，这系列操作都要知道⽤户的身份才⾏。但服务器不知道这些请求是有关联的，每次都要问⼀遍身份信息。

对于⽆状态的问题，解法⽅案有很多种，其中⽐较简单的⽅式⽤ **Cookie 技术**。

`Cookie` 通过 **在请求和响应报⽂中写⼊ Cookie 信息来控制客户端的状态**。

##### 明文传输——双刃剑

明⽂意味着在传输过程中的信息，是可⽅便阅读的，通过浏览器的 F12 控制台或 Wireshark 抓包都可以直接⾁眼查看，为调试⼯作带了极⼤的便利性。

但正是这样，HTTP 的所有信息都暴露在了光天化⽇下，相当于信息裸奔。在传输的漫⻓的过程中，信息的内容都毫⽆隐私可⾔，很容易就能被窃取，如果⾥⾯有你的账号密码信息，那你号没了。

##### 不安全

HTTP 比较严重的缺点就是不安全：

- 通信使用明文（不加密），内容可能会被窃听。⽐如，账号信息容易泄漏，那你号没了。
- 不验证通信⽅的身份，因此有可能遭遇伪装。⽐如，访问假的淘宝、拼多多，那你钱没了。
- ⽆法证明报⽂的完整性，所以有可能已遭篡改。⽐如，⽹⻚上植⼊垃圾⼴告，视觉污染，眼没了。

HTTP 的安全问题，可以⽤ HTTPS 的⽅式解决，也就是通过 **引⼊ SSL/TLS 层**，使得在安全上达到了极致。

#### HTTP/1.1 性能

HTTP 协议是基于 **TCP/IP**，并且使⽤了 **「请求 - 应答」** 的通信模式。

##### 1、长连接

早期 HTTP/1.0 性能上的⼀个很⼤的问题，那就是每发起⼀个请求，都要新建⼀次 TCP 连接（三次握⼿），⽽且是串⾏请求，做了⽆谓的 TCP 连接建⽴和断开，增加了通信开销。

为了解决上述 TCP 连接问题，HTTP/1.1 提出了 **⻓连接** 的通信⽅式，也叫持久连接。这种⽅式的好处在于减少了TCP 连接的᯿复建⽴和断开所造成的额外开销，减轻了服务器端的负载。

持久连接的特点是，只要任意⼀端没有明确提出断开连接，则保持 TCP 连接状态。

##### 2、管道网络传输

HTTP/1.1 采⽤了⻓连接的⽅式，这使得管道（pipeline）⽹络传输成为了可能。

即可在同⼀个 TCP 连接⾥⾯，客户端可以发起多个请求，只要第⼀个请求发出去了，不必等其回来，就可以发第⼆个请求出去，可以 **减少整体的响应时间**。

##### 3、队头阻塞

「请求 - 应答」的模式加剧了 HTTP 的性能问题。

因为当顺序发送的请求序列中的⼀个请求因为某种原因被阻塞时，在后⾯排队的所有请求也⼀同被阻塞了，会招致客户端⼀直请求不到数据，这也就是 **「队头阻塞」**。

### 2.3 HTTP 与 HTTPs

#### 两者区别

- HTTP 是超⽂本传输协议，信息是明⽂传输，存在安全⻛险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在TCP 和 HTTP ⽹络层之间加⼊了 **SSL/TLS 安全协议**，使得报⽂能够加密传输；
- HTTP 连接建⽴相对简单， TCP 三次握⼿之后便可进⾏ HTTP 的报⽂传输。⽽ HTTPS 在 TCP 三次握⼿之后，还需进⾏ SSL/TLS 的握⼿过程，才可进⼊加密报⽂传输；
- HTTP 的端⼝号是 **80**，HTTPS 的端⼝号是 **443**；
- HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

HTTP 由于是明⽂传输，所以安全上存在以下三个⻛险：

- **窃听⻛险**，⽐如通信链路上可以获取通信内容；
- **篡改⻛险**，⽐如强制植⼊垃圾⼴告，视觉污染；
- **冒充⻛险**，⽐如冒充淘宝⽹站。

HTTPS 在 HTTP 与 TCP 层之间加⼊了 **SSL/TLS 安全协议**，可以很好的解决上述⻛险：

- **信息加密**：交互信息⽆法被窃取；
- **校验机制**：⽆法篡改通信内容，篡改了就不能正常显示；
- **身份证书**：证明淘宝是真的淘宝⽹。

#### HTTPS 是如何解决上⾯的三个⻛险的

- **混合加密** 的⽅式实现信息的 **机密性**，解决了窃听的⻛险；
- **摘要算法** 的⽅式来实现 **完整性**，它能够为数据⽣成独⼀⽆⼆的「指纹」，指纹⽤于校验数据的完整性，解决了篡改的⻛险；
- 将服务器公钥放⼊到数字证书中，解决了冒充的⻛险。

##### 混合加密

HTTPS 采⽤的是 **对称加密** 和 **⾮对称加密** 结合的「混合加密」⽅式：

- 在通信建⽴前 **采⽤⾮对称加密的⽅式交换「会话秘钥」**，后续就不再使⽤⾮对称加密；
- 在通信过程中全部使⽤对称加密的「会话秘钥」的⽅式加密明⽂数据。

采⽤「混合加密」的⽅式的原因：

- **对称加密** 只使⽤⼀个密钥，**运算速度快**，密钥必须保密，⽆法做到安全的密钥交换；
- **⾮对称加密** 使⽤两个密钥：公钥和私钥，公钥可以任意分发⽽私钥保密，**解决了密钥交换问题** 但速度慢。

##### 摘要算法

客户端在发送明⽂之前会通过摘要算法算出明⽂的「指纹」，发送的时候把「指纹 + 明⽂」⼀同加密成密⽂后，发送给服务器，服务器解密后，⽤相同的摘要算法算出发送过来的明⽂，通过⽐较客户端携带的「指纹」和当前算出的「指纹」做⽐较，若「指纹」相同，说明数据是完整的。

##### 数字证书

借助第三⽅权威机构 `CA （数字证书认证机构）`，将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。

#### HTTPS 是如何建⽴连接的？其间交互了什么？

SSL/TLS 协议基本流程：

- 客户端向服务器索要并验证服务器的公钥；
- 双⽅协商⽣产「会话秘钥」；
- 双⽅采⽤「会话秘钥」进⾏加密通信。

SSL/TLS 协议建⽴的详细流程：

##### 1、Client Hello

⾸先，由客户端向服务器发起加密通信请求，也就是 ==Client Hello 请求==。

- 客户端⽀持的 SSL/TLS 协议版本；客户端⽣产的随机数，后⾯⽤于⽣产「会话秘钥」；客户端⽀持的密码套件列表，如 RSA 加密算法。

##### 2、Server Hello

服务器收到客户端请求后，向客户端发出响应，也就是 ==Sever Hello== 。

- 确认 SSL/ TLS 协议版本，如果浏览器不⽀持，则关闭加密通信；服务器⽣产的随机数（ Server Random ），后⾯⽤于⽣产「会话秘钥」；确认密码套件列表，服务器的数字证书。

##### 3、客户端回应

客户端收到服务器的回应之后，⾸先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。

如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使⽤它加密报⽂，向服务器发送信息：

- 一个随机数，该随机数会被服务器公钥加密；
- 加密通信算法改变通知，表示随后的信息都将用会话密钥加密通信；
- 客户端握⼿结束通知，表示客户端的握⼿阶段已经结束。这⼀项同时把之前所有内容的发送数据做个摘
  要，⽤来供服务端校验。

##### 4、服务器最后响应

服务器收到客户端的第三个随机数后，通过协商的加密算法，计算出本次通信的「会话秘钥」。然后，向客户端发送最后的消息：

- 加密通信算法改变通知，表示随后的信息都将用会话密钥加密通信；
- 服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发送数据做个摘要，用来供客户端校验；

⾄此，整个 SSL/TLS 的握⼿阶段全部结束。接下来，客户端与服务器进⼊加密通信，就完全是使⽤普通的 HTTP 协议，只不过⽤「会话秘钥」加密内容。

### HTTP 1.1 可以如何优化？

- 尽量避免发送 HTTP 请求：对于⼀些具有重复性的 HTTP 请求，⽐如每次请求得到的数据都⼀样的，我们可以把这对「请求-响应」的数据都 **缓存** 在本地，那么下次就直接读取本地的数据；
  - 客户端会把第⼀次请求以及响应的数据保存在本地磁盘上，其中将请求的 URL 作为 key，⽽响应作为 value，两者形成映射关系。
- 减少 HTTP 请求次数
  - **减少重定向请求次数**：重定向的⼯作交由代理服务器完成，就能减少 HTTP 请求次数了
  - **合并请求**：把多个访问⼩⽂件的请求合并成⼀个⼤的请求，虽然传输的总资源还是⼀样，但是减少请求，也就意味着减少了重复发送的 HTTP 头部，也减少 TCP 连接的数量，因⽽省去了 TCP 握⼿和慢启动过程耗费的时间；
  - **延迟发送请求**：当前不需要的资源，没必要也获取过来，于是可以通过 **按需获取** 的⽅式，来减少第⼀时间的 HTTP 请求次数。
- 减少 HTTP 响应的数据大小：**压缩**
  - 无损压缩
  - 有损压缩

### 2.3 HTTP 2.0 优化

#### 头部压缩

HTTP/1.1 报文中 Header 部分存在的问题：

- 含有很多固定字段， 比如 Cookie，User Agent，Accept等，这些字段加起来可能高达几百字节甚至上千字节，所以有必要 **压缩**；
- ⼤量的请求和响应的报⽂⾥有很多字段值都是重复的，这样会使得⼤量带宽被这些冗余的数据占⽤了，所以有必须要 **避免重复性**；
- 字段是 ASCII 编码的，虽然易于⼈类观察，但效率低，所以有必要 **改成⼆进制编码**；

#### 二进制帧

HTTP/2 厉害的地⽅在于将 HTTP/1 的⽂本格式改成 **⼆进制格式传输数据**，极⼤提⾼了 HTTP 传输效率，⽽且⼆进制数据使⽤位运算能⾼效解析。

#### 并发传输

HTTP/1.1 的实现基于 **请求-响应模型**。同⼀个连接中，HTTP 完成⼀个事务（请求与响应），才能处理下⼀个事务，也就是说在发出请求等待响应的过程中，是没办法做其他事情的，如果响应迟迟不来，那么后续的请求是⽆法发送的，也造成了 **队头阻塞** 的问题。

HTTP/2 通过 **Stream** 这个设计，**多个 Stream 复⽤⼀条 TCP 连接，达到并发的效果**，解决了HTTP/1.1 队头阻塞的问题，提⾼了 HTTP 传输的吞吐量。

多个 Stream 只需复⽤ 1 个 TCP 连接，节约了 TCP 和 TLS 握⼿时间，以及减少了 TCP 慢启动阶段对流量的影响。不同的 Stream ID 才可以并发，即时乱序发送帧也没问题，但是同⼀个Stream ⾥的帧必须严格有序。

#### 服务器主动推送资源

HTTP/1.1 不⽀持服务器主动推送资源给客户端，都是由客户端向服务器发起请求后，才能获取到服务器响应的资源。

服务器在推送资源时，会通过 `PUSH_PROMISE` 帧传输 HTTP 头部，并通过帧中的 `Promised Stream ID` 字段告知客户端，接下来会在哪个 **偶数号 Stream** 中发送包体。

#### HTTP 2.0 问题

HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，**TCP 层必须保证收到的字节数据是完整且连续的**，这样内核才会将缓冲区⾥的数据返回给 HTTP 应⽤，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区⾥，只有等到这 1 个字节数据到达时，HTTP/2 应⽤层才能从内核中拿到数据，这就是 **HTTP/2 队头阻塞问题**。

![HTTP协议演化.PNG](https://i.loli.net/2021/08/20/EIerBO4iRbFVpyt.png)

### HTTP 3.0

HTTP/2 通过头部压缩、⼆进制编码、多路复⽤、服务器推送等新特性⼤幅度提升了 HTTP/1.1 的性能，⽽美中不⾜的是 HTTP/2 协议是基于 TCP 实现的，于是存在的缺陷有三个：

- 对头阻塞
- TCP 与 TLS 的握手时延
- 网络迁移需要重新连接

#### 对头阻塞

HTTP/2 多个请求是跑在⼀个 TCP 连接中的，那么当 TCP 丢包时，整个 TCP 都要等待重传，那么就会阻塞该TCP 连接中的所有请求。

#### TCP 与 TLS 的握手时延

发起 HTTP 请求时，需要经过 TCP 三次握⼿和 TLS 四次握⼿（TLS 1.2）的过程，因此共需要 **3 个 RTT 的时延** 才能发出请求数据。

另外， TCP 由于具有 **拥塞控制** 的特性，所以刚建⽴连接的 TCP 会有个 **慢启动** 的过程，它会对 TCP 连接产⽣"减速"效果。

#### ⽹络迁移需要重新连接

**⼀个 TCP 连接是由四元组（源 IP 地址，源端⼝，⽬标 IP 地址，⽬标端⼝）确定的，这意味着如果 IP 地址或者端⼝变动了，就会导致需要 TCP 与 TLS 重新握⼿**，这不利于移动设备切换⽹络的场景。

上面这些问题都是 TCP 协议固有的问题，⽆论应⽤层的 HTTP/2 在怎么设计都⽆法逃脱。要解决这个问题，就必须 **把传输层协议替换成 UDP**。

#### QUIC 协议

HTTP/3 不仅仅只是简单将传输协议替换成了 UDP，还 **基于 UDP 协议在「应⽤层」实现了 QUIC 协议，它具有类似 TCP 的连接管理、拥塞窗⼝、流量控制的⽹络特性，相当于将不可靠传输的 UDP 协议变成“可靠”的了**，所以不⽤担⼼数据包丢失的问题。QUIC 协议的优点：

##### 无队头阻塞

QUIC 协议也有类似 HTTP/2 Stream 与多路复⽤的概念，也是可以在同⼀条连接上并发传输多个 Stream，Stream可以认为就是⼀条 HTTP 请求。

由于 QUIC 使⽤的传输协议是 UDP，UDP 不关⼼数据包的顺序，如果数据包丢失，UDP 也不关⼼。

但 QUIC 协议会保证数据包的可靠性，每个数据包都有⼀个序号唯⼀标识。当某个流中的⼀个数据包丢失了，即使该流的其他数据包到达了，数据也⽆法被 HTTP/3 读取，直到 QUIC 重传丢失的报⽂，数据才会交给 HTTP/3。⽽其他流的数据报⽂只要被完整接收，HTTP/3 就可以读取到数据。这与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。

所以，**QUIC 连接上的多个 Stream 之间并没有依赖，都是独⽴的**，某个流发⽣丢包了，只会影响该流，其他流不受影响。

##### 更快的连接建立

对于 HTTP/1 和 HTTP/2 协议，**TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层**，因此它们难以合并在⼀起，需要分批次来握⼿，先 TCP 握⼿，再 TLS 握⼿。

QUIC 内部包含 TLS1.3，因此仅需 1 个 RTT 就可以「同时」完成建⽴连接与 TLS 密钥协商，甚⾄在第⼆次连接的时候，应⽤数据包可以和 QUIC 握⼿信息（连接信息 + TLS 信息）⼀起发送，达到 0-RTT 的效果。

##### 连接迁移

QUIC 协议没有⽤四元组的⽅式来“绑定”连接，⽽是通过 **连接 ID** 来标记通信的两个端点，客户端和服务器可以各⾃选择⼀组 ID 来标记⾃⼰，因此即使移动设备的⽹络变化后，导致 IP 地址变化了，只要仍保有上下⽂信息（⽐如连接 ID、TLS 密钥等），就可以“⽆缝”地复⽤原连接，消除重连的成本，没有丝毫卡顿感，达到了连接迁移的功能。

## 三、TCP篇

### 3.1 TCP基础

#### 1、TCP基本认识

##### TCP 头部格式

![TCP头.PNG](https://i.loli.net/2021/08/09/NIFQgTZwpyvJOsx.png)

**序列号SYN**：在建⽴连接时由计算机⽣成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送⼀次数据，就「累加」⼀次该「数据字节数」的⼤⼩。⽤来 **解决⽹络包乱序问题**。

**确认应答号ACK**：指下⼀次 **期望收到的数据的序列号**，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。⽤来 **解决不丢包的问题**。

**控制位**：

- `ACK`：该位为 1 时，「确认应答」的字段变为有效，TCP 规定除了最初建⽴连接时的 SYN 包之外该位必须设置为 1；
- `RST`：该位为 1 时，表示 TCP 连接中 **出现异常必须强制断开连接**；
- `SYN`：该位为 1 时，表示 **希望建⽴连接**，并在其「序列号」的字段进⾏序列号初始值的设定；
- `FIN`：该位为 1 时，表示今后不会再有数据发送，**希望断开连接**。

##### 为什么需要 TCP 协议

IP 层是 **不可靠** 的，它不保证⽹络包的交付、不保证⽹络包的按序交付、也不保证⽹络包中的数据的完整性。

如果需要 **保障⽹络数据包的可靠性**，那么就需要由上层（传输层）的 TCP 协议来负责。

因为 TCP 是⼀个⼯作在 **传输层的可靠数据传输的服务**，它能确保接收端接收的⽹络包是 **⽆损坏、⽆间隔、⾮冗余和按序的**。

##### 什么是 TCP

TCP 是 **⾯向连接的、可靠的、基于字节流** 的传输层通信协议。

- 面向连接：**一对一**才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息；
- 可靠的：⽆论⽹络链路中出现了怎样的链路变化，TCP 都可以保证⼀个报⽂⼀定能够到达接收端；
- 字节流：消息是「没有边界」的，所以⽆论我们消息有多⼤都可以进⾏传输。并且消息是「有序的」，当「前⼀个」消息没有收到的时候，即使它先收到了后⾯的字节，那么也不能扔给应⽤层去处理，同时对「重复」的报⽂会⾃动丢弃。

##### 什么是 TCP 连接

⽤于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括 **Socket、序列号和窗⼝⼤⼩** 称为连接。

因此，建⽴⼀个 TCP 连接是需要客户端与服务器端达成上述三个信息的共识：

- **Socket**：由 IP 地址和端口号组成；
- **序列号**：用来解决乱序问题；
- **窗口大小**：用来实现流量控制。

##### 唯一地确定一个 TCP 连接

TCP 四元组可以唯⼀的确定⼀个连接，四元组包括：**源地址、源端口、目的地址、目的端口**。

- 源地址和目的地址的字段（32位）在 **IP 头部** 中，作用是通过 IP 协议发送报文给对方主机；

- 源端口和目的端口的字段（16位）在 **TCP头部** 中，作用是告诉 TCP 协议应该把报文发送给哪个进程。

##### 有一个 IP 的服务器监听了一个端口，它的 TCP 最大连接数是多少

服务器通常固定在某个本地端口上监听，等待客户端的连接请求。

因此，客户端 IP 和 端口是可变的，其理论值计算公式如下：
$$
Maxmum_{TCP}=IP_{client}*Port_{client}
$$
对于 $IPv4$，客户端的 IP 数最多为 $2^{32}$，客户端的端口数最多为 $2^{16}$，即服务器的最大 TCP 连接数，约为 $2^{48}$。

当然，实际场景中，服务端的最大并发 TCP 连接数远不能达到理论上限。

- 首先主要是 **文件描述符限制**，Socket 都是文件，所有要通过 `ulimit` 配置文件描述符的数目；
- 其次是 `内存限制`，每个 TCP 连接都要占用一定的内存，而操作系统的内存是有限的。

##### 为什么 UDP 头部有包长度字段，而 TCP 头部则没有

TCP 计算负载数据长度公式：
$$
TCP_{data} = IP_{len}-IP_{header}-TCP_{header}
$$
UDP 也可以通过类似的方式计算。因此 UDP 头部中的包长度字段实际是 **冗余的**。

（另一种理解：**为了⽹络设备硬件设计和处理⽅便，⾸部⻓度需要是 4 字节的整数倍**。）

#### 2、TCP 连接建立

TCP 是⾯向连接的协议，所以使⽤ TCP 前必须先建⽴连接，⽽建⽴连接是通过 **三次握⼿** 来进⾏的。

<img src="https://i.loli.net/2021/08/09/JAxY2UbOaBkI1um.png" alt="三次握手.PNG" style="zoom: 80%;" />

- 初始，客户端和服务端都处于 `CLOSED` 状态。先是服务端主动监听某个端口，处于 `LISTEN` 状态；

![第一个SYN报文.PNG](https://i.loli.net/2021/08/09/9dFKszWNVcg3Gve.png)

- 客户端随机初始化序号（`client_isn`），将此序号置于 TCP 首部的 `序列号` 字段中，同时把 `SYN` 标志位置为 ==1==，表示 ==SYN报文==。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 `SYN_SENT` 状态；

![第二个报文.PNG](https://i.loli.net/2021/08/09/MEf8py7uSQtAZ96.png)

- 服务端收到客户端的 ==SYN 报文== 后，首先服务端也随机初始化自己的序号（`server_isn`），将此序号填入TCP 首部的 `序列号` 字段中，其次把 TCP 首部的 `确认应答号` 字段填入 `client_isn+1`，同时把 `SYN` 和 `ACK` 标志位置为 ==1==。最后把该报文发送给客户端，该报文也不包含应用层数据，之后服务端处于 `SYN-RCVD` 状态。

![第三个报文.PNG](https://i.loli.net/2021/08/09/G7QIlENvFWTKCmo.png)

- 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，把 `ACK` 标志位置为 ==1==，其次在 `确认应答号` 字段填入 `server_isn+1`，最后把报文发送给服务端，这次报文可以携带客户到服务器的数据，之后客户端处于 `ESTABLISHED` 状态。
- 服务器收到客户端的应答报文后，也进入 `ESTABLISHED` 状态。

##### 为什么需要三次握手？

###### 原因一：避免历史连接

三次握手的首要原因是 **为了防止旧的重复连接初始化造成混乱**。

<img src="https://i.loli.net/2021/08/09/AVbZgdMfoWJI8nt.png" alt="三次握手避免历史连接.PNG" style="zoom: 67%;" />

举个例子，客户端连续发送多次 `SYN` 建立连接的报文，在 **网络拥堵** 情况下：

- 一个 「旧 SYN 报⽂」⽐「最新的 SYN 」 报⽂早到达了服务端；
- 那么此时服务端就会回⼀个 ==SYN + ACK 报⽂== 给客户端；
- 客户端收到后可以根据⾃身的上下⽂，**判断这是⼀个历史连接（序列号过期或超时）**，那么客户端就会发送==RST 报⽂== 给服务端，表示中⽌这⼀次连接

如果是两次握手连接，服务端收到一个失效的报文后，会误认为是一个新的连接请求，于是会发出一个确认报文，同意建立连接。但是客户端并没有发出建立连接的请求，因此不会去向服务端发送数据，服务端没有收到数据就会一直等待，这样 **服务端就会浪费掉很多资源**。

###### 原因二：同步双方初始序列号

TCP 协议的通信双⽅， 都必须维护⼀个「序列号」， 序列号是可靠传输的⼀个关键因素，它的作⽤：

- 接收方可以去除重复的数据；
- 接收方可以根据数据包的序列号按序接收；
- 可以标识发送出去的数据包中，哪些是已经被对方收到的；

当客户端发送携带「初始序列号」的 ==SYN 报⽂== 的时候，需要服务端回⼀个 ==ACK 应答报⽂==，表示客户端的 SYN 报⽂已被服务端成功接收，那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，这样**⼀来⼀回，才能确保双⽅的初始序列号能被可靠的同步**。

<img src="https://i.loli.net/2021/08/09/2RvHeJcLd4BkWs3.png" alt="同步序列号.PNG"  />

四次握⼿其实也能够可靠的同步双⽅的初始化序号，但由于 **第⼆步和第三步可以优化成⼀步**，所以就成了 **三次握⼿**。

###### 原因三：避免资源浪费

如果客户端的 **SYN 阻塞**了，重复发送多次 SYN 报⽂，那么服务器在收到请求后就会建⽴多个冗余的⽆效链接，造成不必要的资源浪费。

<img src="https://i.loli.net/2021/08/09/4JZ8qMPIxs71bij.png" alt="资源浪费.PNG" style="zoom:67%;" />

不使用「两次握⼿」和「四次握⼿」的原因：

- 「两次握⼿」：⽆法防⽌历史连接的建⽴，会造成双⽅资源的浪费，也⽆法可靠的同步双⽅序列号；

- 「四次握⼿」：三次握⼿就已经理论上最少可靠连接建⽴，所以不需要使⽤更多的通信次数。

##### 为什么 TCP 层还需要 MSS？

![MTU和MSS.PNG](https://i.loli.net/2021/08/09/lvdcKrJesCEDagx.png)

- `MTU`：一个网络包的最大长度，以太网中一般为 ==1500 字节==；
- `MSS` ：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度；

当 IP 层有⼀个超过 `MTU` ⼤⼩的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进⾏分⽚，把数据分⽚成若⼲⽚，保证每⼀个分⽚都⼩于 `MTU`。把⼀份 IP 数据报进⾏分⽚以后，由⽬标主机的 IP 层来进⾏重新组装后，再交给上⼀层 TCP 传输层。

**当其中一个 IP 分片丢失，整个IP 报文的所有分片都需要重传**。

 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责处理超时和重传。

当接收⽅发现 TCP 报⽂（头部 + 数据）的某⼀⽚丢失后，则不会响应 ACK 给对⽅，那么发送⽅的 TCP 在超时后，就会 **重发「整个 TCP 报⽂（头部 + 数据）」**。

因此，由 IP 层进⾏分⽚传输，是⾮常没有效率的。

为了达到最佳的传输效能， TCP 协议在 **建⽴连接的时候通常要协商双⽅的 MSS 值**，当 TCP 层发现数据超过MSS 时，则就先会进⾏分⽚，当然由它形成的 IP 包的⻓度也就不会⼤于 MTU ，⾃然也就不⽤ IP 分⽚了。

经过 TCP 层分⽚后，如果⼀个 TCP 分⽚丢失后，**进⾏重发时也是以 MSS 为单位**，⽽不⽤重传所有的分⽚，⼤⼤增加了重传的效率。

##### SYN 攻击与防范

###### SYN 攻击

 TCP 连接建⽴是需要三次握⼿，假设攻击者短时间伪造不同 IP 地址的 SYN 报⽂，服务端每接收到⼀个 SYN 报⽂，就进⼊ SYN_RCVD 状态，但服务端发送出去的 ACK + SYN 报⽂，⽆法得到未知 IP 主机的 ACK 应答，久⽽久之就会 **占满服务端的 SYN 接收队列（未连接队列）**，使得服务器不能为正常⽤户服务。

###### 避免方式一

修改 Linux 内核参数，控制队列⼤⼩和当队列满时应做什么处理。

- **增大半连接队列**：要想增⼤半连接队列，不能只单纯增⼤ `tcp_max_syn_backlog` 的值，还需⼀同增⼤ `somaxconn` 和 `backlog`，也就是 **增⼤全连接队列**
- 超出处理能力，对新的 `SYN` 直接回 `RST`，丢弃连接：`net.ipv4.tcp_abort_on_overflow`。
- 通常情况下，应当把 `tcp_abort_on_overflow` 设置为 0，因为这样更 **有利于应对突发流量**。举个例⼦，当 TCP 全连接队列满导致服务器丢掉了 ACK，与此同时，客户端的连接状态却是 `ESTABLISHED`，进程就在建⽴好的连接上发送请求。只要服务器没有为请求回复 ACK，请求就会被多次重发。如果服务器上的进程只是短暂的繁忙造成 accept 队列满，那么当 TCP 全连接队列有空位时，再次接收到的请求报⽂由于含有 ACK，仍然会触发服务器端成功建⽴连接。`tcp_abort_on_overflow` 设为 0 可以提⾼连接建⽴的成功率，只有你⾮常肯定 TCP 全连接队列会⻓期溢出时，才能设置为 1 以尽快通知客户端。

###### 避免方式二

先来看下 Linux 内核的 SYN （未完成连接建⽴）队列与 Accpet （已完成连接建⽴）队列是如何⼯作的：

<img src="https://i.loli.net/2021/08/09/BvN89Roq3aHrxZ7.png" alt="正常流程.PNG" style="zoom: 80%;" />

如果不断受到 `SYN 攻击`，就会导致 SYN 队列被占满。

==tcp_syncookies== 可以应对 `SYN 攻击`：

``` c
net.ipv4.tcp_syncookies = 1
```

<img src="https://i.loli.net/2021/08/09/16uDGpOQmkb8vcN.png" alt="syncookies.PNG" style="zoom:80%;" />

- 当「 SYN 队列」满之后，后续服务器收到 SYN 包，不进⼊「 SYN 队列」；
- 计算出⼀个 ==cookie 值==，再以 SYN + ACK 中的「序列号」返回客户端，
- 服务端接收到客户端的应答报⽂时，服务器会检查这个 ACK 包的合法性。如果合法，直接放⼊到「 Accept 队列」。
- 最后应⽤通过调⽤ ==accpet()== socket 接⼝，从「 Accept 队列」取出的连接。

###### 减少 SYN+ACK 重传次数

当服务端受到 SYN 攻击时，就会有⼤量处于 `SYN_REVC` 状态的 TCP 连接，处于这个状态的 TCP 会重传SYN+ACK ，当重传超过次数达到上限后，就会断开连接。那么针对 SYN 攻击的场景，我们可以减少 SYN+ACK 的重传次数，以加快处于 SYN_REVC 状态的 TCP 连接断开。

可以通过修改 `tcp_synack_retries` 参数实现。

#### 3、TCP 连接断开

TCP 断开连接是通过 **四次挥⼿** ⽅式。

双⽅都可以主动断开连接，断开连接后主机中的「资源」将被释放。

<img src="https://i.loli.net/2021/08/09/al4pDn2kuNYJAOC.png" alt="四次挥手.PNG" style="zoom:80%;" />

- 客户端打算关闭连接，会发送一个 TCP 首部 `FIN` 标志位被置为 1 的报文，即 ==FIN 报文==，之后客户端进入 `FIN_WAIT_1` 状态；
- 服务器端收到该报文后，会向客户端发送 ==ACK 应答报文==，接着服务器端进入 `CLOSED_WAIT` 状态；
- 客户端收到服务器端的 ==ACK 应答报文后==，进入 `FIN_WAIT_2` 状态；
- 等待服务器端处理完数据后，也向客户端发送 ==FIN 报文==，之后服务器进入 `LAST_ACK` 状态；
- 客户端收到服务器端的 ==FIN 报文== 后，回一个 ==ACK 应答报文==，之后进入 `TIME_WAIT` 状态；
- 服务器端收到了  ==ACK 应答报文==后，进入 `CLOSED` 状态，⾄此服务端已经完成连接的关闭；
- 客户端在经过 ==2MSL== 一段时间后，自动进入 `CLOSED` 状态，⾄此客户端也完成连接的关闭。

##### 为什么需要四次挥手？

- 关闭连接时，客户端向服务端发送 ==FIN 报文== 时，仅仅表示客户端不再发送数据了但是还能接收数据。
- 服务器收到客户端的 ==FIN 报⽂== 时，先回⼀个 ==ACK 应答报⽂==，⽽服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 FIN 报⽂给客户端来表示同意现在关闭连接。

服务端通常 **需要等待完成数据的发送和处理**，所以服务端的 ACK 和 FIN ⼀般都会 **分开发送**，从⽽⽐三次握⼿导致多了⼀次。

##### 为什么 TIME_WAIT 等待的时间时 2MSL

`MSL` 是 **Maximum Segment Lifetime，报⽂最大生存时间**，它是任何报⽂在⽹络上存在的最⻓时间，超过这个时间报⽂将被丢弃。

`MSL` 与 `TTL` 的区别： `MSL` 的单位是 **时间**，⽽ `TTL` 是 **经过路由跳数**。所以 MSL 应该要⼤于等于 TTL 消耗为 0 的时间，以确保报⽂已被⾃然消亡。

`TIME_WAIT` 等待 2 倍的 `MSL`，⽐较合理的解释是： 可以保证在两个传输方向上的尚未接收到或者迟到的报文段已经消失，~~否则如果服务器立即重启，可能会收到来自上一个进程迟到的数据，但是这种数据很可能是错误的~~，同时也是在理论上保证最后一个报文可靠到达，假设最后一个 `ACK` 丢失，那么服务器会再重发一个 `FIN`，这时虽然客户端的进程不在了，但是 TCP 连接还在，仍然可以重发 `LAST_ACK`，⼀来⼀去正好 2 个 MSL。

==2MSL== 的时间是从客户端接收到 ==FIN 报文== 后发送 ==ACK 应答报文== 开始计时的。**如果在 `TIME-WAIT` 时间内，因为客户端的 ==ACK 应答报文== 没有传输到服务端，客户端⼜接收到了服务端重发的 ==FIN 报文== ，那么 2MSL 时间将重新计时**。

在 Linux 系统⾥ ==2MSL==  默认是 60 秒，那么⼀个 MSL 也就是 30 秒。

##### 为什么需要 TIME_WAIT 状态

主动发起关闭连接的一方，才会有 `TIME_WAIT` 状态。原因包括：

- 防⽌具有相同「四元组」的「旧」数据包被收到；
- 保证「被动关闭」的⼀⽅能被正确的关闭，即保证最后的 `ACK` 能让被动关闭⽅接收，从⽽帮助其正常关闭；

###### 防止旧连接的数据包

当一个TCP连接处于 `TIME_WAIT` 状态时，我们无法使用该连接的端口来建立一个新连接。反过来思考，假设 `TIME_WAIT` 没有等待时间或时间过短，则应用程序能够立即建立一个和刚关闭的连接相似的连接，这是如果被延迟的数据包抵达了客户端，那么客户端是有可能正常接收这个过期的报⽂，这就会产⽣数据错乱等严重的问题。

经过 ==2MSL== 的时间，⾜以让两个⽅向上的数据包都被丢弃，使得原来连接的数据包在⽹络中都⾃然消失，再出现的数据包⼀定都是新建⽴连接所产⽣的。

![TIME_WAIT过短.PNG](https://i.loli.net/2021/08/25/3W2gkDmEro6VhZT.png)

###### 保证连接正确关闭

`TIME-WAIT` 作⽤是 **等待⾜够的时间以确保最后的 ACK 能让被动关闭⽅接收，从⽽帮助其正常关闭**。

假设 `TIME_WAIT` 没有等待时间或时间过短，断开连接会造成什么问题呢？

![TIME_WAIT.PNG](https://i.loli.net/2021/08/09/oDjLAm2brFH7GS6.png)

- 如上图红⾊框框客户端四次挥⼿的最后⼀个 ==ACK 报⽂== 如果在⽹络中被丢失了，此时如果客户端 `TIME-WAIT ` 过短或没有，则就直接进⼊了` CLOSED` 状态了，那么服务端则会⼀直处在 `LASE_ACK` 状态。
- 当客户端发起建⽴新连接的 ==SYN 请求报⽂== 后，服务端会发送 ==RST 报⽂== 给客户端，新连接建⽴的过程就会被终⽌。

如果 `TIME-WAIT` 等待⾜够⻓的情况就会遇到两种情况：

- 服务端正常收到四次挥⼿的最后⼀个 ==ACK 报⽂==，则服务端正常关闭连接；
- 服务端没有收到四次挥⼿的最后⼀个 ==ACK 报⽂== 时，则会重发 ==FIN报文== 关闭连接，并等待新的 ==ACK 报⽂==。

##### TIME_WAIT 过多的危害

有处于 `TIME-WAIT` 状态的 TCP，则说明是由该⽅ **主动发起** 的断开请求。

 过多的 `TIME-WAIT` 状态主要的危害有两种：

- 内存资源占用；
- 对端口资源的占用，一个 TCP 连接消耗一个本地端口；

如果发起连接⼀⽅的 `TIME_WAIT` 状态过多，占满了所有端⼝资源，则会导致 **⽆法创建新连接**。

客户端受端口资源限制：

- 客户端 `TIME_WAIT` 过多，就会导致端⼝资源被占⽤，因为端⼝就 65536 个，被占满就会导致⽆法创建新的连接。

服务器端受系统资源限制：

- 由于⼀个四元组表示 TCP 连接，理论上服务端可以建⽴很多连接，服务端确实只监听⼀个端口，但是会把连接扔给处理线程，所以理论上监听的端口可以继续监听。但是线程池处理不了那么多⼀直不断的连接了。所以当服务端出现⼤量 `TIME_WAIT` 时，系统资源被占满时，会导致处理不过来新的连接

##### 建立连接后，客户端挂掉

TCP 有⼀个 **保活机制**，用于处理这种情况：定义⼀个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作⽤，**每隔⼀个时间间隔，发送⼀个探测报⽂**，该探测报⽂包含的数据⾮常少，如果连续⼏个探测报⽂都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应⽤程序。

开启了 **TCP 保活机制** 后，存在以下⼏种情况：

- 对端程序正常⼯作。当 TCP 保活的探测报⽂发送给对端, 对端会正常响应，这样 TCP 保活时间会被 **重置**，等待下⼀个 TCP 保活时间的到来。
- 对端程序崩溃并重启。当 TCP 保活的探测报⽂发送给对端后，对端是可以响应的，但由于没有该连接的有效信息，会产⽣⼀个 ==RST 报⽂==，这样很快就会发现 TCP 连接已经被重置。
- 对端程序崩溃，或对端由于其他原因导致报⽂不可达。当 TCP 保活的探测报⽂发送给对端后，⽯沉⼤海，没有响应，连续⼏次，达到保活探测次数后，TCP 会报告该 TCP 连接已经死亡。

##### 产生 RST 的三个条件

- 目的地为某端口的 SYN 到达，然而该端口上没有正在监听的服务器；
- TCP 想取消一个已有连接；
- TCP 接收到一个根本不存在的连接上的分节；

##### TCP 状态流转图：

![TCP 状态流转图.png](https://i.loli.net/2021/08/13/ieDIul6X4yJOHZx.png)

- **CLOSED**：初始状态；
- **LISTEN**：服务器端的某个 `socket` 处于监听状态，可以接受连接；
- **SYN_SEND**：
- **SYN_RCVD**：
- **FIN_WAIT_1**：已经建立连接后，其中一方主动请求终止连接，等待对方的 ==FIN 报文==；
- **FIN_WAIT_2**：半关闭状态；出现在关闭连接时，客户端和服务器两次挥手之后的状态；在这个状态下，主动关闭一方还有接收数据的能力，但是已经无法发送数据；
- **TIME_WAIT**：
- **CLOSING**：如果双方几乎同时关闭一个 `socket` 的话，就会出现同时发送 ==FIN 报文== 的情况，此时双方进入 **CLOSING** 状态，表示双方都正在关闭 `socket` 连接；
- **CLOSE_WAIT**：被动关闭一方收到 ==FIN 报文==，并回复 ==ACK 报文== 后，处于的状态；等待没有数据需要发出后，向对方发送一个 ==FIN 报文==，进入 `LAST_ACK` 状态；
- **LAST_ACK**：被动关闭的一方发送 ==FIN 报文== 后，等待对方的 ==ACK 报文==；

### 3.2 TCP 重传、滑动窗口、流量控制、拥塞控制

#### 重传机制

TCP 实现可靠传输的⽅式之⼀，是通过 **序列号与确认应答**。

在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回⼀个确认应答消息，表示已收到消息。

<img src="https://i.loli.net/2021/08/09/pfyXunks2w1DLK3.png" alt="序列号与确认应答.PNG" style="zoom:80%;" />

TCP 针对数据包丢失的情况，会⽤ **重传机制** 解决，常见的重传机制包括：

- 超时重传
- 快速重传
- SACK
- D-SACK

##### 超时重传

重传机制的其中⼀个⽅式，就是在发送数据时，设定⼀个定时器，当超过指定的时间后，没有收到对⽅的 ACK 确认应答报⽂，就会重发该数据，也就是我们常说的超时重传。

TCP 会在以下两种情况发生超时重传：

- 数据包丢失
- 确认应答丢失

![超时重传.PNG](https://i.loli.net/2021/08/09/fJtTH2A9NDu1bSz.png)

###### RTT 与 RTO

**RTT（往返时延）**：从发送端发送数据开始，到发送端收到来自接收端的确认总共经历的时间，即 **包的往返时间**；

**RTO（超时重传时间）**

![RTO与RTT.PNG](https://i.loli.net/2021/08/09/ehrSpQAqmGLkd2K.png)

两种超时时间不同的情况：

- 当超时时间 **RTO 较大** 时，丢包后过很久才重发，没有效率，性能差；
- 当超时时间 **RTO 较小** 时，会导致可能并没有丢就重发，于是重发的就快，会增加⽹络拥塞，导致更多的超时，更多的超时导致更多的重发。

**超时重传时间 RTO 的值应该略⼤于报⽂往返 RTT 的值**。

如果超时重发的数据，再次超时的时候，⼜需要重传的时候，TCP 的策略是 **超时间隔加倍**。

每当遇到⼀次超时重传的时候，都会将下⼀次超时时间间隔设为先前值的两倍。两次超时，就说明⽹络环境差，不宜频繁反复发送。

##### 快速重传

快速重传机制不以 时间为驱动，而是 **以数据驱动重传**。

![快速重传.PNG](https://i.loli.net/2021/08/09/DaZoBPWzqIxkpVT.png)

快速重传的⼯作⽅式是当 **收到三个相同的 ACK 报⽂时，会在定时器过期之前，重传丢失的报⽂段**。

##### SACK 方法

SACK （ Selective Acknowledgment **选择性确认**）：需要在 TCP 头部「选项」字段⾥加⼀个 ==SACK== 的东⻄，它可以 **将缓存的地图发送给发送⽅**，这样发送⽅就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以 **只重传丢失的数据**。

![SACK.PNG](https://i.loli.net/2021/08/09/k6xZQC89uNfXthn.png)

在 Linux 下，可以通过 `net.ipv4.tcp_sack` 参数打开这个功能。

##### Duplicate SACK

Duplicate SACK ⼜称 D-SACK ，其主要功能是 **使⽤ SACK 来告诉「发送⽅」有哪些数据被重复接收了**。

D-SACK 有这么⼏个好处：

- 可以让「发送⽅」知道，是发出去的包丢了，还是接收⽅回应的 ACK 包丢了；
- 可以知道是不是「发送⽅」的数据包被⽹络延迟了；
- 可以知道⽹络中是不是把「发送⽅」的数据包给复制了；

在 Linux 下，可以通过 `net.ipv4.tcp_dsack` 参数打开/关闭这个功能。

#### 滑动窗口

为每个数据包确认应答的缺点：包的往返时间越长，网络的吞吐量会越低，即通信效率越低。

为解决这个问题，TCP 引⼊了 **窗⼝** 这个概念。窗口大小是指 **⽆需等待确认应答，⽽可以继续发送数据的最⼤值**。

窗⼝的实现实际上是操作系统开辟的⼀个缓存空间，发送⽅主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。

![滑动窗口累计确认.PNG](https://i.loli.net/2021/08/09/2efXFlZ8CUvkAEq.png)

图中的 ACK 600 确认应答报⽂丢失，也没关系，因为可以通过下⼀个确认应答进⾏确认，只要发送⽅收到了 ACK 700 确认应答，就意味着 700 之前的所有数据「接收⽅」都收到了。这个模式就叫 **累计确认** 或者 **累计应答**。

##### 窗口大小由哪一方决定

TCP 头⾥有⼀个字段叫 ==Window== ，也就是窗⼝⼤⼩。

这个字段是 **接收端** 告诉发送端⾃⼰还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能⼒来发送数据，⽽不会导致接收端处理不过来。

所以，通常窗⼝的⼤⼩是 **由接收⽅的窗⼝⼤⼩** 来决定的。

##### 发送方的滑动窗口

![发送方滑动窗口1.PNG](https://i.loli.net/2021/08/09/J7fXbQa1rPTkUSR.png)

- #1 是已发送并收到 ACK 确认的数据：1~31 字节
- #2 是已发送但未收到 ACK 确认的数据：32~45 字节
- #3 是未发送但总⼤⼩在接收⽅处理范围内（接收⽅还有空间）：46~51字节
- #4 是未发送但总⼤⼩超过接收⽅处理范围（接收⽅没有空间）：52字节以后

在下图，当发送⽅把数据「全部」都⼀下发送出去后，可⽤窗⼝的⼤⼩就为 0 了，表明可⽤窗⼝耗尽，在没收到 ACK 确认之前是⽆法继续发送数据了。

![发送滑动窗口2.PNG](https://i.loli.net/2021/08/09/cQ6hUHxTEp4CYz1.png)

在下图，当收到之前发送的数据 32~36 字节的 ACK 确认应答后，如果发送窗⼝的⼤⼩没有变化，则 **滑动窗⼝往右边移动 5 个字节**，因为有 5 个字节的数据被应答确认，接下来 52~56 字节⼜变成了可⽤窗⼝，那么后续也就可以发送 `52~56` 这 5 个字节的数据了。

![发送方滑动窗口3.PNG](https://i.loli.net/2021/08/09/osgjCZKSIWEXYNM.png)

##### 接收方滑动窗口

接收窗口相对简单⼀些，根据处理的情况划分成三个部分：

- #1 + #2 是已成功接收并确认的数据（等待应⽤进程读取）；
- #3 是未收到数据但可以接收的数据；
- #4 未收到数据并不可以接收的数据；

![接收方滑动窗口.PNG](https://i.loli.net/2021/08/09/ZVO5DJEWIsUq9Ru.png)

接收窗口和发送窗口大小并不完全相等，因为滑动窗⼝并不是⼀成不变的。⽐如，当接收⽅的应⽤进程读取数据的速度⾮常快的话，这样的话接收窗⼝可以很快的就空缺出来。那么新的接收窗⼝⼤⼩，是通过 TCP 报⽂中的 Window 字段来告诉发送⽅。那么这个传输过程是存在时延的，所以接收窗⼝和发送窗⼝是约等于的关系。

#### 流量控制

TCP 提供⼀种可以让「发送⽅」根据「接收⽅」的实际接收能⼒控制发送数据量的机制，即 **流量控制**。

TCP 是一个 **双工的协议**，会话的双方都可以同时接收、发送数据。TCP 会话的双方都各自维护一个发送窗口和一个接收窗口。

发送窗口和接收窗口中所存放的字节数，都是放在操作系统内存缓冲区中的，⽽操作系统的缓冲区，会被 **操作系统调整**。当应⽤进程没办法及时读取缓冲区的内容时，也会对缓冲区造成影响，举个例子：

当服务端系统资源⾮常紧张的时候，操⼼系统可能会直接减少了接收缓冲区⼤⼩，这时应⽤程序⼜⽆法及时读取缓存数据，那么这时候就有严重的事情发⽣了，会出现数据包丢失的现象。

![滑动窗口.PNG](https://i.loli.net/2021/08/25/pGTdIkOeShtb3Mq.png)

如果发⽣了先减少缓存，再收缩窗口，就会出现丢包的现象；为了防⽌这种情况发⽣，TCP 规定是 **不允许同时减少缓存⼜收缩窗⼝的，⽽是采⽤先收缩窗口，过段时间再减少缓存**，这样就可以避免了丢包情况。

##### 窗口关闭

如果窗⼝⼤⼩为 0 时，就会阻⽌发送⽅给接收⽅传递数据，直到窗⼝变为⾮ 0 为⽌，这就是窗⼝关闭。

**潜在危险**：接收⽅向发送⽅通告窗⼝⼤⼩时，是通过 ACK 报⽂来通告的。如果通告窗⼝不再是 0 的 ACK 报⽂在⽹络中丢失了，那麻烦就⼤了。这会导致发送⽅⼀直等待接收⽅的⾮ 0 窗⼝通知，接收⽅也⼀直等待发送⽅的数据，如不采取措施，这种相互等待的过程，会造成了死锁的现象。

为了解决这个问题，TCP 为每个连接设有⼀个持续定时器，**只要 TCP 连接⼀⽅收到对⽅的零窗⼝通知，就启动持续计时器**。如果持续计时器超时，就会发送 **窗口探测 ( Windowprobe ) 报⽂**，⽽对⽅在确认这个探测报⽂时，给出⾃⼰现在的接收窗口⼤⼩。

- 如果接收窗口仍然为 0，那么收到这个报⽂的⼀⽅就会重新启动持续计时器

窗口探测的次数⼀般为 3 次，每次⼤约 30-60 秒（不同的实现可能会不⼀样）。如果 3 次过后接收窗口还是 0 的话，有的 TCP 实现就会发 ==RST 报⽂== 来中断连接。

##### 糊涂窗口综合征

如果接收⽅太忙了，来不及取⾛接收窗口⾥的数据，那么就会导致发送⽅的发送窗口越来越⼩。

到最后，如果 **接收⽅腾出⼏个字节并告诉发送⽅现在有⼏个字节的窗口，⽽发送⽅会义⽆反顾地发送这⼏个字节**，这就是糊涂窗口综合症。

糊涂窗口综合症的现象是可以发⽣在发送⽅和接收⽅：

- 接收⽅可以通告⼀个小的窗口；
- 发送⽅可以发送小数据。

因此，解决上面两个问题就可以解决糊涂窗口综合症：

- 当 **窗口⼩于 min( MSS，缓存空间/2 )** ，也就是⼩于 MSS 与 1/2 缓存⼤⼩中的最⼩值时，就会向发送⽅通告窗口为 ==0== ，也就阻⽌了发送方再发数据过来；
- 使⽤ `Nagle 算法`（默认打开的），该算法的思路是 **延时处理**，它满⾜以下两个条件中的⼀条才可以发送数据：
  - 要等到窗⼝ >= MSS 或是 数据⼤⼩ >= MSS；
  - 收到之前发送数据的 ACK 回包

如果对于⼀些 **需要⼩数据包交互的场景的程序**，⽐如，telnet 或 ssh 这样的交互性⽐较强的程序，则需要关闭 Nagle 算法。可以在 socket 设置 `TCP_NODELAY` 选项来关闭这个算法：

``` c++
setsockopt(sockfd, IPPROTO_TCP, TCP_NODELAY, (char *)&value, sizeof(int));
```

另外一种解决小数据的方案是 **TCP 延迟确认**：

- 当没有携带数据的 ACK，它的⽹络效率也是很低的，因为它也有 40 个字节的 IP 头 和 TCP 头，但却没有携带数据报⽂，为了解决 ACK 传输效率低问题，所以就衍⽣出了 TCP 延迟确认，其策略为：
  - 当有响应数据要发送时，ACK 会随着响应数据⼀起⽴刻发送给对⽅；
  - 当没有响应数据要发送时，ACK 将会延迟⼀段时间，以等待是否有响应数据可以⼀起发送；
  - 如果在延迟等待发送 ACK 期间，对⽅的第⼆个数据报⽂⼜到达了，这时就会⽴刻发送 ACK。

#### 拥塞控制

流量控制是 **避免「发送⽅」的数据填满「接收⽅」的缓存**，拥塞控制的⽬的就是 **避免「发送⽅」的数据填满整个⽹络**。

##### 拥塞窗口

拥塞窗口 `cwnd` 是发送⽅维护的⼀个的状态变量，它会根据⽹络的拥塞程度动态变化的。

我们在前⾯提到过发送窗口 `swnd` 和接收窗口 `rwnd` 是约等于的关系，那么由于加⼊了拥塞窗口的概念后，此
时发送窗口的值是 $swnd = min(cwnd, rwnd)$，也就是拥塞窗口和接收窗口中的最⼩值。

拥塞窗口 `cwnd` 变化的规则：

- 只要⽹络中没有出现拥塞， `cwnd` 就会增⼤；

- ⽹络中出现了拥塞， `cwnd` 就减少；

只要「发送⽅」没有在规定时间内接收到 ACK 应答报⽂，也就是 **发⽣了超时重传**，就会认为⽹络出现了拥塞。

##### 拥塞控制算法

###### 慢启动

慢启动算法的思路是：不要一开始就发送大量的数据，先探测以下一下网络的拥塞程度，其原理是：

当发送⽅ **每收到⼀个 ACK，拥塞窗口 `cwnd` 的⼤⼩就会加 1**。举个例子：

- 连接建⽴完成后，⼀开始初始化 `cwnd = 1`，表示可以传⼀个 ==MSS== ⼤⼩的数据；

- 当收到⼀个 ACK 确认应答后，`cwnd` 增加 1，于是⼀次能够发送 2 个；
- 当收到 2 个的 ACK 确认应答后， `cwnd` 增加 2，于是就可以⽐之前多发2 个，所以这⼀次能够发送 4 个；

- 当这 4 个的 ACK 确认到来的时候，每个确认 `cwnd` 增加 1， 4 个确认 `cwnd` 增加 4，于是就可以⽐之前多发 4 个，所以这⼀次能够发送 8 个。

![慢启动.PNG](https://i.loli.net/2021/08/09/zPlNIQiMU5dD91Z.png)

有⼀个叫慢启动⻔限 `ssthresh` 状态变量：

- 当 $cwnd < ssthresh$ 时，使用 **慢启动算法**；
- 当 $cwnd \ge ssthresh$ 时，使用 **拥塞避免算法**。

###### 拥塞避免算法

进⼊拥塞避免算法后，它的规则是：**每收到⼀个 ACK 时，`cwnd` 增加 $\frac{1}{cwnd}$**（每经历一个往返时延，`cwnd` 增加1）。

接上前⾯的慢启动的例⼦，现假定 `ssthresh` 为 8 ：

- 当 8 个 ==ACK 确认应答== 到来时，每个确认增加 1/8，8 个 ACK 确认 `cwnd` ⼀共增加 1，于是这⼀次能够发送 9个 `MSS` ⼤⼩的数据，变成了线性增⻓。

![拥塞避免算法.PNG](https://i.loli.net/2021/08/09/9Kd1tw6iourD5fM.png)

拥塞避免算法就是将原本慢启动算法的指数增⻓变成了线性增⻓，还是增⻓阶段，但是增⻓速度缓慢了⼀些。

⼀直增⻓后，网络就会慢慢进⼊拥塞的状况，于是就会出现丢包现象，这时就需要对丢失的数据包进⾏重传。

###### 拥塞发生算法

当⽹络出现拥塞，也就是会发⽣数据包重传，重传机制主要有两种：

- 超时重传
- 快速重传

当发⽣了「超时重传」，则就会使⽤拥塞发⽣算法。

这个时候，`ssthresh` 和 `cwnd` 的值会发⽣变化：

- `ssthresh` 设为 `cwnd/2`；
- `cwnd` 重置为 1.

![拥塞发生算法.PNG](https://i.loli.net/2021/08/09/JKfZ9WtMu3YCeyj.png)

接着，就重新开始慢启动，慢启动是会突然减少数据流的。这真是⼀旦「超时重传」，⻢上回到解放前。但是这种⽅式太激进了，反应也很强烈，会造成⽹络卡顿。

还有更好的⽅式，前⾯我们讲过 **「快速重传算法」**。当接收⽅发现丢了⼀个中间包的时候，发送三次前⼀个包的ACK，于是发送端就会快速地重传，不必等待超时再重传。

TCP 认为这种情况不严重，因为⼤部分没丢，只丢了⼀⼩部分，则 `ssthresh` 和 `cwnd` 变化如下：

- $cwnd = cwmd/2$；
- $ssthresh = cwnd$；
- 进入 **快速恢复算法**。

快速重传和快速恢复算法⼀般同时使⽤，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明⽹络也不那么糟糕，所以没有必要像 ==RTO== 超时那么强烈。

![快速恢复.PNG](https://i.loli.net/2021/08/09/3zceUntIlZsLayW.png)

快速回复算法如下：

- 拥塞窗口 $cwnd=ssthresh+3$;
- 重传丢失的数据包；
- 如果再收到重复的 ACK，那么 `cwnd` 增加 1；
- 如果收到新数据的 ACK 后，把 `cwnd` 设置为第⼀步中的 `ssthresh` 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进⼊拥塞避免状态；

### 3.3 Socket 编程

#### TCP Socket 编程

![TCP_socket.PNG](https://i.loli.net/2021/08/05/1Gj7JDBFmz3o5YO.png)

- 服务端和客户端初始化 `socket`，得到文件描述符；
- 服务端调用 `bind`，绑定 IP 地址和端口；
- 服务端调用 `listen`，监听端口号；
- 服务端调用 `accept`，等待客户端连接；
- 客户端调用 `connect`，向服务器端的地址和端口发起连接请求；
- 服务端 `accept` 返回用于传输的 `socket` 的文件描述符；
- 客户端调用 `write` 写入数据；服务端调用 `read` 读取数据；
- 客户端断开连接时，会调用 `close`，那么服务端 `read` 读取数据时，就会读取到 ==EOF==，待处理完数据后，服务端调用 `close`，表示连接关闭。

服务端调⽤ `accept` 时，连接成功了会返回⼀个 **已完成连接的** `socket`，后续⽤来传输数据。

即监听的 `socket` 和真正用来传送数据的 `socket`，是两个 `socket`，一个叫作 **监听** `socket`，一个叫作 **已完成连接的** `socket`。

##### socket 函数

函数原型如下：

``` c++
int socket(int domain, int type, int protocol);
```

`socket` 函数对应于普通文件的打开操作，用于创建一个 `socket 描述符`，唯一地标识一个 `socket`。

- `domain`：协议族决定了 `socket` 的地址类型；
- `type`：指定 `socket` 类型；SOCK_STREAM、SOCK_DGRAM等；
- `protocol`：指定协议；IPPROTO_TCP、IPPROTO_UDP等。`protocol` 为 0 时，会自动选择 `type` 类型对应的默认协议；

调用 `socket` 函数返回值，没有一个具体的地址。失败返回 `-1`。

##### bind 函数

函数原型如下：

``` c++
int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen);
```

- `sockfd`：`socket 描述字`;
- `addr`：指定要绑定给 `sockfd` 的协议地址，根据创建 `socket` 时的地址协议族不同而不同

``` c
struct sockaddr_in {
    sa_family_t    sin_family;	/* address family: AF_INET */
    in_port_t      sin_port;	/* port in network byte order */
    struct in_addr sin_addr;	/* internet address */
}

struct in_addr {
    uint32_t	   s_addr;
}
```

- `addrlen`：地址长度。

通常服务器启动时都会绑定一个众所周知的地址，用于提供服务；而客户端就不用指定，在 `connect()` 时由系统自动分配一个端口号和自身的 IP 地址组合。

进程可以把一个特定的 IP 地址捆绑到它的套接字上。对于 TCP 客户，这就为在该套接字上发送的 IP 数据报指派了源 IP 地址。对于 TCP 服务器，这就限定该套接字只接收那些目的地为这个 IP 地址的客户连接。

函数执行成功返回值为 `0`，反之为 `SOCKET_ERROR, -1`。

##### listen 函数

- `listen` 函数 **仅由 TCP 服务器调用**，他做两件事情：
  - 当 `socket` 函数创建一个套接字时，他被假设为一个主动套接字，即是一个将调用 `connect` 发起连接的客户套接字。`listen` 函数把一个未连接的套接字转换成一个被动套接字。调用 `listen` 导致套接字从 `CLOSED` 状态转换到 `LISTEN` 状态；
- 第二个参数规定了内核应该为相应套接字排队的最大连接个数。

Linux 内核会维护两个队列：

- 未完成连接队列（SYN 队列）：接收到⼀个 SYN 建⽴连接请求，处于 `SYN_RCVD` 状态；

- 已完成连接队列（Accept 队列）：已完成 TCP 三次握⼿过程，处于 `ESTABLISHED` 状态.

<img src="https://i.loli.net/2021/08/09/8Y2bp5gHMF67uDv.png" alt="内核队列.PNG" style="zoom:80%;" />

``` c
int listen(int socketfd, int backlog)
```

- `socketfd` 为文件描述符
- `backlog` 为相应的 `socket` 可以排队的最大连接个数；

现在通常认为 `backlog` 是 `accept` 队列。

- 在三路握手完成之后，但在服务器调用 `accept` 之前到达的数据应由服务器 TCP 排队，最大数据量为相应已连接套接字的接收缓冲区大小。

##### connect 函数

函数原型如下：

``` c++
int connect(int sockfd, const strucr sockaddr *addr, socklen_t addrlen);
```

- `addr` ：服务器的 `socket` 地址；
- 客户端在调用 `connect` 前不必非得调用 `bind` 函数，因为如果需要的话，内核会确定源 IP 地址，并选择一个临时端口作为源端口；
- 调用 `connect` 将激发 TCP 的三路握手过程，仅在连接建立成功或出错时才返回；出错返回的情况可能包括以下集中：
  - TCP 客户没有收到 SYN 分节的响应，返回 `ETIMEDOUT` 错误。
  - 对客户的SYN的响应是 RST，则表明该服务器主机上在我们指定端口上没有进程在等待与之连接，这是一个 **硬错误**， 返回 `ECONNREFUSED` 错误；
  - 客户发出的 SYN 在中间的某个路由器上引发了一个 ”destination unreachable" ICMP 错误，这是一种 **软错误**。按第一种情况重发，若超过规定时间后，则返回 `EHOSTUNREACH` 或 `ENETUNREACH` 错误。
- `connect` 函数导致当前套接字从 `CLOSED` 状态转移到 `SYN_SENT` 状态，若成功则转移到 `ESTABLISHED` 状态。

##### accept 函数

- `accept` 函数由 TCP 服务器调用，用于从已完成连接队列队头返回下一个已完成连接。如果已完成连接队列为空，那么进程被投入睡眠；

函数原型如下：

``` c++
int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);
```

- 参数 `addr` 和 `addrlen` 用来返回已连接的对端进程的协议地址。
- 如果 `accept` 成功，那么其返回值是由内核自动生成的一个 **全新描述符**，代表与所返回客户的 TCP 连接。
- 通常称 `accept` 的第一个参数为 **监听套接字描述符**，称它的返回值为 **已连接套接字描述符**。一个服务器通常只创建一个监听套接字，它在该服务器的生命期内一直存在。内核为每个由服务器进程接受的客户连接创建一个已连接套接字。当服务器完成对某个给定客户的服务时，相应的已连接套接字就被关闭。

##### accept 发生在三次握手的哪一步

<img src="C:\Users\10295\AppData\Roaming\Typora\typora-user-images\image-20210809143213836.png" alt="image-20210809143213836" style="zoom:80%;" />

- 客户端的协议栈向服务器端发送了 ==SYN 包==，并告诉服务器端当前发送序列号 `client_isn`，客户端进⼊`SYN_SENT` 状态；
- 服务器端的协议栈收到这个包之后，进⾏ ==ACK 应答==，应答的值为 `client_isn+1`，表示对 SYN 包 `client_isn `的确认，同时服务器也发送⼀个 ==SYN 包==，告诉客户端当前我的发送序列号为 `server_isn`，服务器端进⼊ `SYN_RCVD` 状态;
- 客户端协议栈收到 ACK 之后，使得应⽤程序从 `connect` 调⽤返回，表示客户端到服务器端的单向连接建⽴成功，客户端的状态为 `ESTABLISHED`，同时客户端协议栈也会对服务器端的 SYN 包进⾏应答，应答数据为`server_isn+1`；

- 应答包到达服务器端后，服务器端协议栈使得 `accept` 阻塞调⽤返回，这个时候服务器端到客户端的单向连接也建⽴成功，服务器端也进⼊ `ESTABLISHED` 状态。

由上图可知，客户端 `connect` 成功返回是在 **第⼆次握⼿**，服务端 `accept` 成功返回是在 **三次握⼿成功** 之后。

- `accept` 返回的是一个已连接的 `socket描述字 connfd`，与服务器端调用 `socket` 函数得到的 `sockfd` 不同。

##### read/write 函数

函数原型如下：

``` c++
ssize_t read(int fd, void *buf, size_t count);

ssize_t write(int fd, const void *buf, size_t count);
```

- `read()` 函数负责从 `fd` 中读取内容。读取成功时，返回实际所读的字节数，如果返回值为 0，表示已经读到了文件的结束，小于 0 表示出现了错误；
  - `fd`：`socket 描述字`;
  - `buf`：缓冲区；
- `write()` 函数将 `buf` 中的 nbytes 字节内容写入文件描述符 `fd`，成功时返回写的字节数。失败时返回 `-1`，并设置 `errno` 变量。

##### close 函数

- `close` 函数用来关闭套接字，并终止 TCP 连接

``` c++
#include <unistd.h>

int close(int sockfd);
```

- 调用 `close` 函数会将套接字描述符的引用计数减 1，如果减 1 后，引用计数值仍大于 0，这个 `close` 调用并不引发 TCP 的四分组连接终止序列，对于子进程与父进程共享已连接套接字的并发服务器来说，这是期望的；
- 在并发服务器中，如果父进程对每个由 `accept` 返回的已连接套接字都不调用 `close`，会发生：
  - 父进程最终将耗尽可用描述符，因为任何进程在任何时刻可拥有的打开着的描述符数通常是有限制的；
  - 没有一个客户连接会被终止。当子进程关闭已连接套接字时，它的引用计数将由 2 递减为 1 且保持为 1，浙江妨碍 TCP 连接终止序列的发生，导致连接一直打开着。

##### 并发服务器

- 当服务一个客户请求可能花费较长时间时，我们并不希望整个服务器被单个客户长期占用，而是希望同时服务多个客户，一个最简单的方法是 **fork 一个子进程来服务每个客户**；
- 当一个连接建立时，`accept` 返回，服务器接着调用 `fork`，然后由子进程服务客户，父进程则等待另一个连接，父进程关闭已连接套接字；

##### 客户端调用 close 

<img src="https://i.loli.net/2021/08/09/CEUMOJcv9ixbedB.png" alt="socket编程四次挥手.PNG" style="zoom:80%;" />

- 客户端调⽤ `close`，表明客户端没有数据需要发送了，则此时会向服务端发送 ==FIN 报⽂==，进⼊ `FIN_WAIT_1`状态；
- 服务端接收到了 ==FIN 报⽂==，TCP 协议栈会为 FIN 包插⼊⼀个⽂件结束符 EOF 到接收缓冲区中，应⽤程序可以通过 read 调⽤来感知这个 FIN 包。这个 **EOF 会被放在已排队等候的其他已接收的数据之后**，这就意味着服务端需要处理这种异常情况，因为 EOF 表示在该连接上再⽆额外数据到达。此时，服务端进⼊ `CLOSE_WAIT `状态；
- 当处理完数据后，⾃然就会读到 EOF ，于是也调⽤ `close` 关闭它的套接字，这会使得客户端会发出⼀个 ==FIN 报文==，之后处于 `LAST_ACK` 状态；
- 客户端接收到服务端的 FIN 包，并发送 ==ACK 确认包== 给服务端，此时客户端将进⼊ `TIME_WAIT` 状态；
- 服务端收到 ==ACK 确认包== 后，就进⼊了最后的 `CLOSE` 状态；
- 客户端经过 ==2MSL== 时间之后，也进⼊ `CLOSE` 状态。

#### 一个简单的 TCP socket 通信程序

- server.cpp 的代码是：

``` c
#include<stdio.h>
#include<stdlib.h>
#include<string.h>
#include<errno.h>
#include<sys/types.h>
#include<sys/socket.h>
#include<netinet/in.h>
#include<arpa/inet.h>
#include<unistd.h>

#define MAXLINE 4096

int main(int argc, char **argv) {
    int listenfd, connfd;
    struct sockaddr_in servaddr;
    char buff[4096];
    int n;
    
    if ( (listenfd = socket(AF_INET, SOCK_STREAM, 0)) == -1) {
        print("create socket error: %s(errno：%d)\n", strerror(errno), errno);
        return 0;
    } 
    
    memset(&servaddr, 0, sizeof(servaddr));
    servaddr.sin_family = AF_INET;
    servaddr.sin_addr.s_addr = htonl(INADDR_ANY);
    servaddr.sin_port = htons(6666);
    
    if ( bind(listenfd, (struct sockaddr*)&servaddr, sizeof(servaddr)) == -1) {
        printf("bind socket error: %s(errno: %d)\n", strerror(errno), errno);
        return 0;
    }
    
    if (listen(listenfd, 10) == -1) {
        printf("listen socket error: %s(errno: %d)\n", strerror(errno), errno);
        return 0;
    }
    
    printf("=======waiting for client's request=======\n");
    while(1) {
        struct sockaddr_in cliaddr;
        size_t size = sizeof(struct socklen_t);
        if ( (connfd = accept(listenfd, (struct sockaddr*)&cliaddr, (unsigned                           int*)&size)) == -1) {
            printf("accept socket error: %s(errno: %d)\n", strerror(errno), errno);
            continue;
        }
        printf("new connection client %s:%d\n", inet_ntoa(cliaddr.sin_addr),                            ntohs(cliaddr.sin_port));
        n = recv(connfd, buff, MAXLINE, 0);
        buff[n] = '\0';
        printf("resv msg from client: %s\n", buff);
        close(connfd);
    }
    close(connfd);
    return 0;
} 
```

- client.cpp 的代码是：

``` c
#include<stdio.h>
#include<stdlib.h>
#include<string.h>
#include<errno.h>
#include<sys/types.h>
#include<sys/socket.h>
#include<netinet/in.h>
#include<arpa/inet.h>
#include<unistd.h>

#define MAXLINE 4096

int main(int argc, char **argv) {
    int sockfd, n;
    char recvline[4096], sendline[4096];
    struct sockaddr_in servaddr;
    
    if (argc != 2) {
        printf("usage: ./client <ipaddress>\n");
        return 0;
    }
    
    if ( (sockfd = socket(AF_INET, SOCK_STREAM, 0)) < 0) {
        printf("create socket error: %s(errno：%d)\n", strerror(errno), errno);
        return 0;
    }
    
    memset(&servaddr, 0, sizeof(servaddr));
    servaddr.sin_family = AF_INET;
    servaddr.sin_port = htons(6666);
    if ( inet_pton(AF_INET, argv[1], &servaddr.sin_addr) <= 0) {
        printf("inet_pton error for %s\n", argv[1]);
        return 0;
    }
    
    if ( connect(sockfd, (struct sockaddr*)&servaddr, sizeof(servaddr)) < 0) {
        printf("connect socket error: %s(errno：%d)\n", strerror(errno), errno);
        return 0;
    }
    
    printf("send msg to server: \n");
    fgets(sendline, 4096, stdin);
    if ( send(sockfd, sendline, strlen(sendline), 0) < 0) {
        printf("send msg error: %s(errno：%d)\n", strerror(errno), errno);
        return 0;
    }
    
    close(sockfd);
    return 0;
}
```

`inet_pton` 的函数原型为：

``` c
// P 和 n 分别代表表达（presentation）和数值（numeric），地址的表达格式通常是ASCII 字符串，数值格式则是存放到套接字地址结构中的二进制值
int inet_pton(int af, const char *src, void *dst);
```

这个函数负责转换字符串到网络地址，第一个参数 `af` 是地址族，转换后存到 `dst` 中。

### 3.4、TCP 协议选项

- TCP 头部的选项部分是 **为了 TCP 适应复杂的网络环境和更好地服务于应用** 而进行设计的；
- TCP 选项部分最长可以达到 `40 Byte`，再加上 TCP 选项外的固定的 `20 Byte` 部分， TCP的头部最长可达 `60 Byte`；
- TCP 头部长度可以通过 TCP 头部中 **数据偏移位** 来查看：TCP 偏移量的单位是 `32bit` ，也就是 `4 Byte`。 TCP 数据偏移为 共占 `4bit` ，取最大 `1111` 计算也就是十进制的 `15`。$15 * 4Bytes = 60 Bytes$​，这个也 TCP 首部不超过 `60Byte` 的原因。

### 3.5、网络字节序与主机序

- 不同的 CPU 有不同的字节序类型，这些字节序是指 **整数在内存中保存的顺序**，称为 **主机序**;
- 最常见的有两种：
  - **小端**：把地址低位存储值的低位，地址高位存储值的高位；
  - **大端**：把地址低位存储值的高位，地址高位存储值的低位；
- 举个例子，数字 `0x12345678` 在两种字节序 CPU 中的存储顺序如下图所示：

![主机序.PNG](https://i.loli.net/2021/08/13/1F9chWbT4AKnked.png)

- C/C++ 编写的程序里的数据存储顺序跟编译平台所在的 CPU 相关；而 Java 编写的程序采用的是 **大端** 来存储数据；
- 所有网络协议都是采用 **大端** 的方式来传输数据，因此大端也叫做 **网络字节序**。

### 3.6、 封包和解包

- TCP 是个 **“流”协议**，所谓流，就是 **没有界限的一串数据**；

- 由于 TCP “流”的特性以及网络状况，在进行数据传输时假设我们连续调用两次 `send` 分别发送两段数据 data1和 data2，在接收端有以下几种接收情况：

  - 先接收到 data1 ，然后接收到 data2；
  - 先接收到 data1 的部分数据，然后接收到 data1 余下的部分以及 data2 全部；
  - 先接收到了 data1 的全部数据和 data2 的部分数据，然后接收到了 data2 的余下的数据；
  - 一次性接收到了 data1 和 data2 的全部数据；

  对于第一种种情况正是我们需要的， 对于后面三种情况就是常说的 **粘包**，就需要把接收到的数据进行 **拆包**，拆成一个个独立的数据包；而为了拆包就必须在发送端进行 **封包**。

- 对于 UDP 来说就不存在拆包的问题，因为 UDP 是个 **”数据包”协议**，也就是两段数据间是有界限的，在接收端要么接收不到数据要么就是接收一段完整的数据；

- 出现 **粘包** 的原因：

  - **由 Nagle 算法造成的发送端的粘包**；当要提交一段数据给 TCP 发送时， TCP 并不立刻发送此段数据，而是等待一小段时间，看看在等待期间是否还有要发送的数据，若有则会把多段数据发送出去，例如后两种情况；
  - **接收端接收不及时造成的接收端粘包**；TCP 会把接收到的数据存在自己的缓冲区中，然后通知应用层取数据。当应用层由于某些原因不能及时取出 TCP 的数据，就会造成 TCP缓冲区中存放了多段数据；

- 封包就是 **给一段数据加上包头**，这样一来数据包就分为包头和包体两部分内容了；包头其实上是个 **大小固定的结构体**，其中有个结构体成员变量表示 **包体的长度**；

- 根据固定的包头长度以及包头中含有的包体长度的变量值就能正确的拆分出一个完整的数据包。

### 3.7、 TCP 重传参数

- 在 TCP 中，**ACK 报文是不会重传的**。

- TCP 第⼀次握⼿的 SYN 包超时重传最⼤次数是由 `tcp_syn_retries` 指定：

``` shell
cat /proc/sys/net/ipv4/tcp_syn_retries

5/6
```

- TCP 第⼆次握⼿的 SYN、ACK 包超时重传最⼤次数是由 `tcp_synack_retries` 指定：

``` shell
cat /proc/sys/net/ipv4/tcp_synack_retries

5
```

- TCP 建⽴连接后的数据包传输，最⼤超时重传次数是由 `tcp_retries2` 指定：

``` shell
cat /proc/sys/net/ipv4/tcp_retries2

15
```

- 如果第一次挥手丢失了，客户端迟迟收不到被动方的 ACK 的话，也会触发超时重传机制，重传 FIN 报文，重发次数由 `tcp_orphan_retries` 参数控制：

``` shell
cat /proc/sys/net/ipv4/tcp_orphan_retries

0
```

- 对于 `close 函数` 关闭的连接，由于无法再发送和接收数据，所以 `FIN_WAIT2` 状态不可以持续太久，而 `tcp_fin_timeout` 控制了这个状态下连接的持续时长：

``` shell
cat /proc/sys/net/ipv4/tcp_fin_timeout

60
```

- 第三次挥手的 FIN 报文丢失后，服务端就会重发 FIN 报文，重发次数仍然由`tcp_orphan_retries` 参数控制，这与客户端重发 FIN 报文的重传次数控制方式是一样的。
- 如果第四次挥手的 ACK 报文没有到达服务端，服务端就会重发 FIN 报文，重发次数仍然由前面介绍过的 `tcp_orphan_retries` 参数控制。
- 如果要想知道客户端连接不上服务端，是不是服务端 TCP 全连接队列满的原因，那么可以把 `tcp_abort_on_overflow` 设置为 1，这时如果在客户端异常中可以看到很多 ==connection reset by peer== 的错误，那么就可以证明是由于服务端 TCP 全连接队列溢出的问题：
  - 0 ：如果全连接队列满了，那么 server 扔掉 client 发过来的 ack ；
  - 1 ：如果全连接队列满了，server 发送⼀个 ==RST== 包给 client，表示废掉这个握⼿过程和这个连接；

``` shell
cat /proc/sys/net/ipv4/tcp_abort_on_overflow

0
```

- TCP 全连接队列的最大值是 `sk_max_ack_backlog` 变量，取决于 `somaxconn` 和 `backlog` 之间的最小值
  - `somaxconn` 是 Linux 内核的参数，默认值是 128，可以通过`/proc/sys/net/core/somaxconn` 来设置其值；
  - `backlog` 是 `listen(int sockfd, int backlog)` 函数中的 backlog ⼤⼩，Nginx 默认值是 511，可以通过修改配置⽂件设置其⻓度；
- 半连接队列的最大值并不是单由 `max_syn_backlog` 决定，还跟 `somaxconn` 和 `backlog` 有关系：
  - 当 $max\_syn\_backlog > min(somaxconn, backlog)$ 时， 半连接队列最⼤值 $max\_qlen\_log = min(somaxconn, backlog) * 2；$
  - 当 $max\_syn\_backlog < min(somaxconn, backlog)$ 时， 半连接队列最⼤值 $max\_qlen\_log = max\_syn\_backlog * 2$；

#### TCP 第一次握手时会被丢弃的三种条件：

- 如果半连接队列满了，并且没有开启 `tcp_syncookies`，则会丢弃；
- 若全连接队列满了，且没有重传 `SYN+ACK` 包的连接请求多于 1 个，则会丢弃；
- 如果没有开启 `tcp_syncookies`，并且 `tcp_max_syn_backlog` 减去当前半连接队列⻓度⼩于 $(tcp\_max\_syn\_backlog >> 2)$，则会丢弃；

### 3.8、TCP 三次握手性能提升

![三次握手优化.PNG](https://i.loli.net/2021/08/25/YFoDIc5n4KyOjVx.png)

### 3.9、四次挥手性能提升

#### 主动方优化

安全关闭连接的⽅式必须通过四次挥⼿，它由进程调⽤ `close 函数` 和 `shutdown 函数` 发起 FIN 报⽂（`shutdown` 参数须传⼊ `SHUT_WR` 或者 `SHUT_RDWR` 才会发送 FIN）。

#####  close 函数和 shutdown 函数有什么区别

- 调用 `close` 函数会将套接字描述符的引用计数减 1，如果减 1 后，引用计数值仍大于 0，这个 `close` 调用并不引发 TCP 的四分组连接终止序列，对于子进程与父进程共享已连接套接字的并发服务器来说，这是期望的
- 调⽤了 `close 函数` 意味着 **完全断开连接**，完全断开不仅指⽆法传输数据，⽽且也不能发送数据。 此时，调用了`close 函数` 的⼀⽅的连接叫做「孤儿连接」。

- `shutdown 函数`，它可以控制只关闭⼀个⽅向的连接：
  - SHUT_RD(0)：**关闭连接的「读」这个⽅向**，如果接收缓冲区有已接收的数据，则将会被丢弃，并且后续再收到新的数据，会对数据进⾏ ACK，然后悄悄地丢弃。也就是说，对端还是会接收到 ACK，在这种情况下根本不知道数据已经被丢弃了；
  - SHUT_WR(1)：**关闭连接的「写」这个⽅向**，这就是常被称为「半关闭」的连接。如果发送缓冲区还有未发送的数据，将被⽴即发送出去，并发送⼀个 FIN 报⽂给对端；
  - SHUT_RDWR(2)：相当于 SHUT_RD 和 SHUT_WR 操作各⼀次，**关闭套接字的读和写两个方向**。

##### FIN_WAIT1 状态的优化

主动⽅发送 FIN 报⽂后，连接就处于 `FIN_WAIT1` 状态，正常情况下，如果能及时收到被动⽅的 ACK，则会很快变为 `FIN_WAIT2` 状态。如果迟迟收不到对⽅返回的 ACK 时，连接就会⼀直处于 `FIN_WAIT1` 状态。此时，内核会定时重发 FIN 报⽂，其中重发次数由 `tcp_orphan_retries` 参数控制。如果 `FIN_WAIT1` 状态连接很多，我们就需要考虑降低 `tcp_orphan_retries` 的值，当重传次数超过 `tcp_orphan_retries` 时，连接就会直接关闭掉。

当进程调⽤了 `close 函数` 关闭连接，此时连接就会是「孤⼉连接」，因为它⽆法再发送和接收数据。Linux 系统为了防⽌孤⼉连接过多，导致系统资源⻓时间被占⽤，就提供了 `tcp_max_orphans` 参数。如果孤⼉连接数量⼤于它，新增的孤⼉连接将不再⾛四次挥⼿，⽽是 **直接发送 RST 复位报⽂强制关闭**。

##### FIN_WAIT2 状态的优化

当主动⽅收到 ACK 报⽂后，会处于 `FIN_WAIT2` 状态，就表示主动⽅的发送通道已经关闭，接下来将等待对⽅发送FIN 报⽂，关闭对⽅的发送通道。

如果连接是⽤ `shutdown 函数` 关闭的，连接可以⼀直处于 `FIN_WAIT2` 状态，因为它可能还可以发送或接收数据。但对于 `close 函数` 关闭的孤⼉连接，由于⽆法再发送和接收数据，所以这个状态不可以持续太久，⽽`tcp_fin_timeout` 控制了这个状态下连接的持续时⻓，默认值是 60 秒；

##### TIME_WAIT 状态的优化

虽然 `TIME_WAIT` 状态有存在的必要，但它毕竟会消耗系统资源。如果发起连接⼀⽅的 `TIME_WAIT` 状态过多，占满了所有端⼝资源，则会导致⽆法创建新连接。

Linux 提供了 `tcp_max_tw_buckets` 参数，当 `TIME_WAIT` 的连接数量超过该参数时，新关闭的连接就不再经历 `TIME_WAIT` ⽽直接关闭。当服务器的并发连接增多时，相应地，同时处于 `TIME_WAIT` 状态的连接数量也会变多，此时就应当调⼤ `tcp_max_tw_buckets` 参数，减少不同连接间数据错乱的概率。

![四次挥手优化.PNG](https://i.loli.net/2021/08/25/ibYJjMcwzqSW1mC.png)

### 3.10、一个简单的 UDP socket 回射程序

- 大多数 TCP 服务器是并发的，大多数 UDP 服务器是迭代的；

- `recvfrom` 和 `sendto` 函数原型：

``` c++
#include <sys/socket.h>

ssize_t recvfrom(int sockfd, void *buff, size_t nbytes, int flags,
                 struct sockaddr *from, socklen_t *addrlen);

ssize_t sendto(int sockfd, void *buff, ssize_t nbytes, int flags,
               const struct sockaddr *to, socklen_t *addrlen);
```

- 写一个长度为 0 的数据报是可行的。在 UDP 情况下，这会形成一个只包含一个 IP 首部和一个 8 字节 UDP 首部而没有数据的 IP 数据报。

- 服务端代码：

``` c++
#include<stdio.h>
#include<stdlib.h>
#include<string.h>
#include<errno.h>
#include<sys/types.h>
#include<sys/socket.h>
#include<netinet/in.h>
#include<unistd.h>

#define MAXLINE 4096

void dg_echo(int sockfd, struct sockaddr *pcliaddr, socklen_t clilen) {
    int n;
    socklen_t len;
    char mesg[MAXLINE];

    for (;;) {
        len = clilen;
        n = recvfrom(sockfd, mesg, MAXLINE, 0, pcliaddr, &len);

        sendto(sockfd, mesg, n, 0, pcliaddr, len);
    }
}

int main(int argc, char **argv) {
    int sockfd;
    struct sockaddr_in servaddr, cliaddr;
    
    
    if ( (sockfd = socket(AF_INET, SOCK_DGRAM, 0)) == -1) {
        printf("create socket error: %s(errno：%d)\n", strerror(errno), errno);
        return 0;
    } 
    
    memset(&servaddr, 0, sizeof(servaddr));
    servaddr.sin_family = AF_INET;
    servaddr.sin_addr.s_addr = htonl(INADDR_ANY);
    servaddr.sin_port = htons(6666);
    
    if ( bind(sockfd, (struct sockaddr*)&servaddr, sizeof(servaddr)) == -1) {
        printf("bind socket error: %s(errno: %d)\n", strerror(errno), errno);
        return 0;
    }
    
    dg_echo(sockfd, (struct sockaddr*)&cliaddr, sizeof(cliaddr));

    return 0;
} 
```

- 客户端代码：

``` c++
#include<stdio.h>
#include<stdlib.h>
#include<string.h>
#include<errno.h>
#include<sys/types.h>
#include<sys/socket.h>
#include<netinet/in.h>
#include<arpa/inet.h>
#include<unistd.h>

#define MAXLINE 4096

void dg_cli(FILE *fp, int sockfd, const struct sockaddr *pservaddr,                 socklen_t servlen) {
    int n;
    char sendline[MAXLINE], recvline[MAXLINE+1];

    while(fgets(sendline, MAXLINE, fp) != NULL) {
        sendto(sockfd, sendline, strlen(sendline), 0, pservaddr,                        servlen);

        n = recvfrom(sockfd, recvline, MAXLINE, 0, NULL, NULL);

        recvline[n] = 0;
        fputs(recvline, stdout);
    }
}

int main(int argc, char **argv) {
    int sockfd;
    struct sockaddr_in servaddr;
    
    if (argc != 2) {
        printf("usage: ./client <ipaddress>\n");
        return 0;
    }
    
    if ( (sockfd = socket(AF_INET, SOCK_DGRAM, 0)) < 0) {
        printf("create socket error: %s(errno：%d)\n", strerror(errno), errno);
        return 0;
    }
    
    memset(&servaddr, 0, sizeof(servaddr));
    servaddr.sin_family = AF_INET;
    servaddr.sin_port = htons(6666);
    if ( inet_pton(AF_INET, argv[1], &servaddr.sin_addr) <= 0) {
        printf("inet_pton error for %s\n", argv[1]);
        return 0;
    }
    
    dg_cli(stdin, sockfd, (struct sockaddr*)&servaddr,                              sizeof(servaddr));
    
    exit(0);
}
```

### 3.11 UDP 和 TCP 的区别和各自应用场景

UDP 不提供复杂的控制机制，利⽤ IP 提供 **⾯向⽆连接的通信服务**。

UDP 头部如下：

![UDP头.PNG](https://i.loli.net/2021/08/08/AxQ4BeDORGzburE.png)

- TCP 和 UDP 区别：

1. 连接：
   - TCP 是 **面向连接** 的传输层协议，传输数据前先要建立连接。
   - UDP 是 **面向无连接** 
2. 服务对象
   - TCP 是 **一对一的两点服务**
   - UDP 则支持 一对一、一对多、多对多的交互通信
3. 可靠性：
   - TCP 是 **可靠交付数据** 的，数据可以无差错、不丢失、不重复、按需到达；
   - UDP 则是尽最大努力交付，不保证可靠交付数据
4. 拥塞控制、流量控制：
   - TCP **有拥塞控制和流量控制机制**，保证数据传输的安全性；
   - UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。
5. 首部开销：
   - TCP 首部长度较长，会有一定的开销，首部在没有使用 `选项` 字段时是 ==20 字节==，如果使用了 `选项` 字段，则会更长；
   - UDP 首部只有 ==8 字节==，并且是固定不变的，开销较小。
6. 传输方式：
   - TCP 是 **流式传输**，没有边界，但保证顺序和可靠；
   - UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。
7. 分片不同：
   - TCP 的数据⼤⼩如果 **⼤于 MSS **，则会 **在传输层进⾏分⽚**，⽬标主机收到后，也同样 **在传输层组装 TCP数据包**，如果中途丢失了⼀个分⽚，只需要传输丢失的这个分⽚；
   - UDP 的数据⼤⼩如果 **⼤于 MTU **，则会 **在 IP 层进⾏分⽚**，⽬标主机收到后，在 **IP 层组装完数据**，接着再传给传输层，但是如果中途丢了⼀个分⽚，在实现可靠传输的 UDP 时则就需要 **重传所有的数据包**，这样传输效率⾮常差，所以通常 UDP 的报⽂应该⼩于 MTU。

- UDP 的优势：
  - UDP 支持广播和多播；
  - UDP 没有连接建立和拆除；

#### 何时用 UDP 代替 TCP

- 对于广播和多播应用程序必须使用 UDP；
- 对于简单的请求-应答应用程序可以使用 UDP，**不过错误检测功能必须加到应用程序内部**；
- 对于海量数据传输不应该使用 UDP。

### 3.12、给 UDP 应用增加可靠性

- 如果想要让请求——应答式应用程序使用 UDP,那么必须在客户程序中增加以下两个特性：
  - **超时和重传**：用于处理丢失的数据报；
  - **序列号**：供客户验证一个应答是否匹配相应的请求；
- 增加序列号比较简单。客户为每一个请求冠以一个序列号，服务器必须在返送给客户的应答中回射这个序列号；

## 四、IP 篇

### 4.1、IP 基础知识

⽹络层的主要作⽤是：**实现主机与主机之间的通信，也叫点对点（end to end）通信**。

#### 网络层与数据链路层的关系

MAC 的作⽤则是实现「直连」的两个设备之间通信，⽽ IP 则负责在「没有直连」的两个⽹络之间进⾏通信传输。

![网络层与数据链路层.PNG](https://i.loli.net/2021/08/10/XlB8sPjG6EUFfkH.png)

源 IP 地址和⽬标 IP 地址在传输过程中是不会变化的，只有源 MAC 地址和⽬标 MAC ⼀直在变化。

### 4.2 IP 地址

#### IP 地址分类

<img src="https://i.loli.net/2021/08/10/6ykwqSIZC5lXGQe.png" alt="IP地址分类.PNG" style="zoom:80%;" />

黄色部分表示分类，用以区分 IP 地址类别。

##### A、B、C类地址

对于 A、B、C 类地址主要分为两个部分，分别是 **⽹络号** 和 **主机号**。

![三类地址.PNG](https://i.loli.net/2021/08/10/CPbYWzosAmqKIeF.png)

为在 IP 地址中，有两个 IP 是特殊的，分别是主机号全为 1 和 全为 0 地址。

- 主机号全为 1 指定某个网络下的所有主机，用于广播
- 主机号全为 0 指定某个网络

##### 广播

⼴播地址可以分为本地⼴播和直接⼴播两种。

- **在本⽹络内⼴播的叫做本地⼴播**。例如⽹络地址为 `192.168.0.0/24` 的情况下，⼴播地址是 `192.168.0.255` 。因为这个⼴播地址的 IP 包会被路由器屏蔽，所以不会到达 `192.168.0.0/24` 以外的其他链路上。

- **在不同⽹络之间的⼴播叫做直接⼴播**。例如⽹络地址为 `192.168.0.0/24` 的主机向 `192.168.1.255/24` 的⽬标地址发送 IP 包。收到这个包的路由器，将数据转发给 `192.168.1.0/24`，从⽽使得所有`192.168.1.1~192.168.1.254` 的主机都能收到这个包（由于直接⼴播有⼀定的安全问题，多数情况下会在路由器上设置为不转发。） 。

![广播.PNG](https://i.loli.net/2021/08/10/oRipJgaltAfcqHL.png)

##### D、E类地址

D 类和 E 类地址是没有主机号的，所以不可⽤于主机 IP，D 类常被⽤于 **多播**，E 类是预留的分类，暂时未使⽤。

##### 多播地址

多播⽤于 **将包发送给特定组内的所有主机**。

由于 **⼴播⽆法穿透路由**，若想给其他⽹段发送同样的包，就可以使⽤可以穿透路由的多播。

![多播.PNG](https://i.loli.net/2021/08/10/L5dzWsPna8GS9Yk.png)

##### IP 地址分类的优缺点

优点：简单明了、选路简单

缺点：

1. **同⼀⽹络下没有地址层次**，⽐如⼀个公司⾥⽤了 B 类地址，但是可能需要根据⽣产环境、测试环境、开发环境来划分地址层次，⽽这种 IP 分类是没有地址层次划分的功能，所以这就缺少地址的灵活性。

2. 不能很好的与现实网络匹配：
   - C 类地址能包含的最⼤主机数量太少了，只有 254 个；
   - B 类地址能包含的最⼤主机数量⼜太多了

#### 无分类地址 CIDR

这种⽅式不再有分类地址的概念，32 ⽐特的 IP 地址被划分为两部分，前⾯是 **⽹络号**，后⾯是 **主机号**。

表示形式 `a.b.c.d/x`，其中 `/x` 表示前 x 位属于 **网络号**，x 的范围是 `0 ~ 32`，这使得 IP 地址更加具有灵活性。

![CIDR.PNG](https://i.loli.net/2021/08/10/UXu6DL7OvAyVWaF.png)

还有另⼀种划分⽹络号与主机号形式，叫作 **⼦⽹掩码**，掩码的意思就是掩盖掉主机号，剩余的就是⽹络号。

**将⼦⽹掩码和 IP 地址按位 &，就可得到⽹络号**。

<img src="https://i.loli.net/2021/08/10/5p4Z79bYSwQF3Bj.png" alt="子网掩码.PNG" style="zoom:80%;" />

##### 为什么要分离网络号和主机号

因为两台计算机要通讯，⾸先要判断是否处于同⼀个⼴播域内，即⽹络地址是否相同。如果⽹络地址相同，表明接收⽅在本⽹络上，那么可以把数据包直接发送到⽬标主机。

##### 子网划分

可以通过⼦⽹掩码划分出⽹络号和主机号，那实际上⼦⽹掩码还有⼀个作⽤，那就是 **划分⼦⽹**。

子网划分实际上是将主机地址分为两个部分：**子网⽹络地址** 和 **子网主机地址**。

假设对 C 类⽹络地址 `192.168.1.0`，使⽤⼦⽹掩码 `255.255.255.192` 对其进⾏⼦⽹划分。

C 类地址中前 24 位是⽹络号，最后 8 位是主机号，根据⼦⽹掩码可知从 8 位主机号中借⽤ 2 位作为⼦⽹号。

![子网划分.PNG](https://i.loli.net/2021/08/10/lXCkAcruT6VvZeg.png)

由于⼦⽹⽹络地址被划分成 2 位，那么⼦⽹地址就有 4 个，分别是 00、01、10、11，具体划分如下图：

<img src="https://i.loli.net/2021/08/10/k7fYpsQhSjU51nZ.png" alt="子网.PNG" style="zoom: 67%;" />

#### 公有 IP 地址与私有 IP 地址

![公有IP与私有IP.PNG](https://i.loli.net/2021/08/10/s2OaUZqubIimt86.png)

#### IP 地址与路由控制

IP地址的⽹络地址这⼀部分是⽤于进⾏ **路由控制**。

![路由控制.PNG](https://i.loli.net/2021/08/10/17ZQoGvg6CpIjim.png)

- 主机 A 要发送⼀个 IP 包，其源地址是 `10.1.1.30` 和⽬标地址是 `10.1.2.10`，由于没有在主机 A 的路由表找到与⽬标地址 `10.1.2.10` 的⽹络地址，于是包被转发到 **默认路由（路由器 1 ）**

- 路由器 1 收到 IP 包后，也在路由器 1 的路由表匹配与⽬标地址相同的⽹络地址记录，发现匹配到了，于是就把 IP 数据包转发到了 `10.1.0.2` 这台路由器 2

- 路由器 2 收到后，同样对⽐⾃身的路由表，发现匹配到了，于是把 IP 包从路由器 2 的 `10.1.2.1` 这个接⼝出去，最终经过交换机把 IP 数据包转发到了⽬标主机

**环回地址** 是在同⼀台计算机上的程序之间进⾏⽹络通信时所使⽤的⼀个默认地址。

计算机使⽤⼀个特殊的 IP 地址 `127.0.0.1` 作为环回地址。与该地址具有相同意义的是⼀个叫做 `localhost` 的主机名。使⽤这个 IP 或主机名时，数据包不会流向⽹络。

#### IP 分片与重组

最常⻅数据链路是以太⽹，它的 MTU 是 1500 字节。

当 IP 数据包⼤⼩⼤于 MTU 时， IP 数据包就会被 **分片**。

经过分⽚之后的 IP 数据报在被重组的时候，只能由 **⽬标主机** 进⾏，路由器是不会进⾏重组的。

假设发送⽅发送⼀个 4000 字节的⼤数据报，若要传输在以太⽹链路，则需要把数据报分⽚成 3 个⼩数据报进⾏传输，再交由接收⽅重组成⼤数据报。

在分⽚传输中，⼀旦某个分⽚丢失，则会造成整个 IP 数据报作废，所以 TCP 引⼊了 `MSS` 也就是在 TCP 层进⾏分⽚不由 IP 层分⽚，那么对于 UDP 我们尽量不要发送⼀个⼤于 MTU 的数据报⽂。

#### IPv6 基本认识

 IPv6 的地址是 ==128 位==，

### 4.3、IP 协议相关技术

 #### DNS 域名解析

DNS 中的域名都是⽤句点来分隔的，⽐如 `www.server.com`，这⾥的句点代表了不同层次之间的界限。

在域名中，越靠右的位置表示其层级越⾼。

##### 域名解析过程

浏览器⾸先看⼀下⾃⼰的缓存⾥有没有，如果没有就向操作系统的缓存要，还没有就检查本机 **域名解析⽂件**`hosts` ，如果还是没有，就会 DNS 服务器进⾏查询，查询的过程如下：

1. 客户端⾸先会发出⼀个 DNS 请求，问 `www.server.com` 的 IP 是啥，并发给本地 DNS 服务器（也就是客户端的 TCP/IP 设置中填写的 DNS 服务器地址）;
2. 本地域名服务器收到客户端的请求后，如果缓存⾥的表格能找到 `www.server.com`，则它直接返回 IP 地址。如果没有，本地 DNS 会去问它的根域名服务器。根域名服务器是最⾼层次的，它不直接⽤于域名解析，但能指明⼀条道路。
3. 根 DNS 收到来⾃本地 DNS 的请求后，发现后置是 .com，说：“`www.server.com` 这个域名归 `.com` 区域管理”，我给你 `.com` 顶级域名服务器地址给你，你去问问它吧。”

4. 本地 DNS 收到顶级域名服务器的地址后，发起请求;
5. 顶级域名服务器说：“我给你负责 `www.server.com` 区域的权威 DNS 服务器的地址，你去问它”；
6. 本地 DNS 于是转向问权威 DNS 服务器：“⽼三，`www.server.com` 对应的 IP 是啥呀？” `server.com` 的权威DNS 服务器，它是域名解析结果的原出处；
7. 权威 DNS 服务器查询后将对应的 IP 地址 `x.x.x.x` 告诉本地 DNS；
8. 本地 DNS 再将 IP 地址返回客户端，客户端和⽬标建⽴连接。

![DNS域名解析.PNG](https://i.loli.net/2021/08/10/X5VYfHaFgIcTkLC.png)

#### ARP 与 RARP 协议

##### ARP

在传输⼀个 IP 数据报的时候，确定了源 IP 地址和⽬标 IP 地址后，就会通过主机「路由表」确定 IP 数据包下⼀跳。然⽽，⽹络层的下⼀层是数据链路层，所以我们还要知道「下⼀跳」的 **MAC 地址**。

由于主机的路由表中可以找到下⼀跳的 IP 地址，所以可以通过 ARP 协议，求得下⼀跳的 MAC 地址。

ARP 是借助 **ARP 请求** 与 **ARP 响应** 两种类型的包确定 MAC 地址的。

<img src="https://i.loli.net/2021/08/10/4uo95AxpL832Rci.png" alt="ARP协议.PNG" style="zoom:80%;" />

- 主机通过 **广播发送 ARP 请求**， 这个包中包含了想要知道的 MAC 地址的主机 IP 地址；
- 当同个链路中的所有设备收到 ARP 请求时，会去拆开 ARP 请求包⾥的内容，如果 ARP 请求包中的⽬标 IP地址与⾃⼰的 IP 地址⼀致，那么这个设备就将⾃⼰的 MAC 地址塞⼊ **ARP 响应包** 返回给主机。

操作系统通常会把第⼀次通过 ARP 获取的 MAC 地址缓存起来，以便下次直接从缓存中找到对应 IP 地址的 MAC 地址。

##### RARP

ARP 协议是已知 IP 地址求 MAC 地址，那 **RARP 协议** 正好相反，它是已知 MAC 地址求 IP 地址。

通常这需要架设⼀台 RARP 服务器，在这个服务器上注册设备的 MAC 地址及其 IP 地址。然后再将这个设备接⼊到⽹络，接着：

- 该设备会发送⼀条「我的 MAC 地址是 `xxxx`，请告诉我，我的 IP 地址应该是什么」的请求信息；

- RARP 服务器接到这个消息后返回「MAC地址为 `xxxx` 的设备，IP 地址为 `xxxx`」的信息给这个设备。

#### DHCP 动态获取 IP 地址

<img src="https://i.loli.net/2021/08/10/da19w7sYycpQ4Wx.png" alt="DHCP.PNG" style="zoom:80%;" />

DHCP 客户端进程监听的是 68 号端口，DHCP 服务端进程监听的是 67 号端口。

DHCP 工作流程包括 4 个步骤：

- 客户端⾸先发起 **DHCP 发现报⽂（DHCP DISCOVER）** 的 IP 数据报，由于客户端没有 IP 地址，也不知道DHCP 服务器的地址，所以使⽤的是 **UDP ⼴播通信**，其使⽤的⼴播⽬的地址是 `255.255.255.255`（端口
  67） 并且使⽤ 0.0.0.0（端口 68） 作为源 IP 地址。DHCP 客户端将该 IP 数据报传递给链路层，链路层然后
  将帧⼴播到所有的⽹络中设备。

- DHCP 服务器收到 DHCP 发现报⽂时，⽤ DHCP 提供报⽂（DHCP OFFER） 向客户端做出响应。该报⽂仍然使⽤ IP ⼴播地址 `255.255.255.255`，该报⽂信息携带服务器提供可租约的 IP 地址、⼦⽹掩码、默认⽹关、DNS 服务器以及 IP 地址租⽤期。

- 客户端收到⼀个或多个服务器的 DHCP 提供报⽂后，从中选择⼀个服务器，并向选中的服务器发送 **DHCP 请求报⽂（DHCP REQUEST）**进⾏响应，回显配置的参数。

- 最后，服务端⽤ **DHCP ACK 报⽂** 对 DHCP 请求报⽂进⾏响应，应答所要求的参数。

⼀旦客户端收到 DHCP ACK 后，交互便完成了，并且客户端能够在租⽤期内使⽤ DHCP 服务器分配的 IP 地址。

可以发现，DHCP 交互中，全程都是使⽤ **UDP ⼴播通信**。

#### NAT 网络地址转换

![NAT.PNG](https://i.loli.net/2021/08/10/1RHg4fNYQ2n8z53.png)

#### ICMP 协议

**ICMP** 全称是 Internet Control Message Protocol，也就是互联⽹控制报⽂协议。

ICMP 主要的功能包括：**确认 IP 包是否成功送达⽬标地址、报告发送过程中 IP 包被废弃的原因和改善⽹络设置等**。

在 IP 通信中如果某个 IP 包因为某种原因未能达到⽬标地址，那么这个具体的原因将由 ICMP 负责通知。

### 4.4 网络 IO 模型

#### 四种网络 IO 模型

IO 有两种操作，**同步 IO** 和 **异步 IO**。 同步 IO 指的是，必须等待 IO 操作完成后，控制权才返回给用户进程；异步 IO 则是，无须等待 IO 操作完成，就将控制权返回给用户进程。

网络中的IO常见的有以下4种情况：

- 输入操作：等待数据到达套接字接收缓冲区；
- 输出操作：等待套接字发送缓冲区有足够的空间容纳将要发送的数据；
- 服务器接收连接请求：等待新的客户端连接请求的到来；
- 客户端发送连接请求：等待服务器回送客户发起的SYN对应的ACK。

当一个网络 IO （假设是 read ）发生时，它会涉及两个系统对象，**一个是调用这个 IO 的进程，另一个是系统内核**。当一个 read 操作发生时，它会经历两个阶段：**等待数据准备**；**将数据从内核拷贝到进程中**。

##### 1、阻塞 IO 模型

- 阻塞和非阻塞的概念描述的是用户线程调用内核 IO 操作的方式：阻塞是指 IO 操作需要彻底完成后才返回到用户空间；而非阻塞是指 IO 操作被调用后立即返回给用户一个状态值，不需要等到 IO 操作彻底完成。
- 阻塞 IO 模型的特点就是 IO 执行的两个阶段（等待数据和拷贝数据）都被阻塞了；
- 大部分的 socket 接口都是阻塞型的。所谓阻塞型接口是指系统调用时（一般是 IO 接口）却不返回调用结果，并让当前线程一直处于阻塞状态，只有当该系统调用获得结果或者超时出错时才返回结果；
- 一个简单的改进方案是在服务端使用 **多线程（或多进程）**。多线程（或多进程）的目的是让每个连接都拥有独立的线程（或进程），这样任何一个连接的阻塞都不会影响其他的连接。传统意义上，进程的开销要远远大于线程，所以如果需要同时为较多的客户端提供服务，则不推荐使用多进程；如果单个服务执行体需要消耗较多的 CPU 资源，例如需要进行大规模或长时间的数据运算或文件访问，则推荐使用较为安全的进程。
- 如果要同时响应成百上千路的连接请求，则无论多线程还是多进程都会严重占据系统资源，降低系统对外界响应的效率，而线程与进程本身也更容易进入假死状态。
- 很多程序员可能会考虑使用“线程池”或“连接池”。“线程池”旨在降低创建和销毁线程的频率，使其维持一定合理数量的线程，并让空闲的线程重新承担新的执行任务。“连接池”是指维持连接的缓存池，尽量重用已有的连接，降低创建和关闭连接的频率。“线程池”和“连接池”技术也只是在一定程度上缓解了频繁调用 IO 接口带来的资源占用 而且，所谓“池”始终有其上限，**当请求大大超过上限时，“池”构成的系统对外界的响应并不比没有“池”的时候效果好多少**。

##### 2、非阻塞 IO 模型

- 在非阻塞式 IO 中，用户进程其实需要 **不断地主动询问** kernel 数据是否准备好，非阻塞的接口相比于阻塞型接口的显著差异在于 **被调用之后立即返回**；使用如下的函数可以将某句柄归设为非阻塞状态

``` c
fcntl(fd, F_SETFL, O_NOBLOCK);
```

- 在非阻塞状态下， `recv()` 接口在被调用后立即返回，返回值代表了不同的含义，如下所述:
  - 返回值大于 0，表示接收数据完毕，返回值即是接收到的字节数；
  - 返回 0，表示连接已经正常断开；
  - 返回 -1，且 `errno` 等于 **EAGAIN**，表示 `recv` 操作还没执行完成；
  - 返回 -1，且 `errno` 不等于 **EAGAIN**，表示 `recv` 操作遇到系统错误 errno;
- 循环调用 `recv()` 将大幅度占用 CPU 使用率；

##### 3、多路 IO 复用模型

- 多路 IO 复用，有时也称为事件驱动 IO。实现 **一个线程可以监视多个文件句柄**；一旦某个文件句柄就绪，就能够通知应用程序进行相应的读写操作；没有文件句柄就绪时会阻塞应用程序，交出cpu。多路是指网络连接，复用指的是同一个线程；
- IO 复用使用场合：
  - 客户处理多个描述符（通常是交互式输入和网络套接字）时；
  - 一个 TCP 服务器既要处理监听套接字，又要处理已连接套接字；
  - 一个服务器既要处理 TCP，又要处理 UDP；
- 它的基本原理就是有个函数（如 `select` ）会 **不断地轮询所负责的所有 socket** ，当某个 socket 有数据到达了，就通知用户进程；![多路IO复用.PNG](https://i.loli.net/2021/08/31/fP9Kya3JTIQHpRL.png)
- 当用户进程调用了 `select`，那么整个进程会被阻塞，而同时，内核会“监视”所有 `select` 负责的 `socket`，当任何一个 `socket` 中的数据准备好了， `select` 就会返回 这个时候用户进程再调用 `read` 操作，将数据从内核拷贝到用户进程；
- 这个模型和阻塞 IO 的模型其实并没有太大的不同， 事实上还更差一些。因为这里需要使用两个系统调用（ `select` 和 `recvfrom` ）；用 `select` 的优势在于它可以同时处理多个连接；所以，如果处理的连接数不是很高的话，使用 `select/epoll` Web server 定比使用多线程的阻塞 IO Web server 性能更好，可能
  延迟还更大；**`select/poll` 的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接**；
- 在多路复用 IO 模型中，对于每一个 `socket`，一般都设置成为非阻塞的，但是，整个用户的进程其实是一直被阻塞的，只不过进程是被 `select` 这个函数阻塞，而不 `socket` IO 阻塞。

##### 4、信号驱动式 IO 模型

- 也可以通过信号，让内核在描述符就绪时发送 SIGIO 信号通知进程；

![信号驱动式IO模型.PNG](https://i.loli.net/2021/08/31/hc1l74pqsdeSiZg.png)

- 这种模型的优势在于等待数据报到达期间进程不被阻塞，主循环可以继续执行，只要等待来自信号处理函数的通知；

##### 5、异步 IO 模型

- 用户进程发起 read 操作之后，立刻就可以开始去做其他的事；而另一方面，从内核的角度，当它收到一个异步的 read 请求操作之后，首先会立刻返回，所以不会对用户进程产生任何阻塞 然后，内核会等待数据准备完成，然后将数据拷贝到用户内存中，当这一切都完成之后，内核会给用户进程发送一个信号，返回 read 操作已完成的信息；

各个 IO 模型的对比：

- 阻塞式IO模型、非阻塞式IO模型、IO复用模型和信号驱动式IO模型都是同步IO模型。

![网络IO模型.PNG](https://i.loli.net/2021/08/13/rGdv3YMtzbTP67N.png)

- 在非阻塞 IO中，虽然进程大部分时间都不会被阻塞，但是它仍然要求进程去主动检查，并且当数据准备完成以后，也需要进程主动地再次调用 `recvfrom` 来将数据拷贝到用户内存中；
- 异步 IO 则完全不同，它就像是用户进程将整个 IO 操作交给了他人（内核）完成，然后内核做完后发信号通知 在此期间，用户进程不需要去检查 IO 操作的状态，也不需要主动地拷贝数据。

### select 函数

- 该函数允许进程指示内核等待多个事件中的任何一个发生，并只在有一个或多个事件发生或经历一段指定的时间后才唤醒它。

`select` 函数原型：

``` c
int select(int maxfdp1, fd_set *readfds, fd_set *writefds, fd_set *errorfds, struct timeval *timeout);
```

这里面用到了两个结构体：`fd_set` 和 `timeval`。结构体 `fd_set` 可以理解为一个集合，这个集合中存放的是文件描述符，一个 `socket` 就是一个文件，`socket` 描述符就是一个文件描述符；`time_val` 是一个常用的结构，用来代表时间值，有两个成员，一个是秒数，另一个是毫秒数。

``` c
fd_set set;
FD_ZERO(&set);			/* 将 set 清零 */
FD_SET(fd, &set);		/* 将 fd 加入 set 中 */
FD_CLR(fd, &set);		/* 将 fd 从 set 中清除 */
FD_ISSET(fd, &set);		/* 如果 fd 在 set 中为真 */
```

- `maxfdp` 是一个整数值，是指集合中所有文件描述符的范围，即所有文件描述符的最大值加 `1`；
- `readfds` 是指向 `fd_set` 结构的指针，这个集合中应该包括文件描述符。因为要监视文件描述符的读变化的，即关心是否可以从这些文件中读取数据，如果这个集合中有一个文件可读， `select` 就会返回一个大于 `0` 的值，表示有文件可读；
- `writefds` 是指向 `fd_set` 结构的指针，这个集合中应该包括文件描述符。因为要监视文件描述符的写变，即关心是否可以向这些文件中写入数据，如果这个集合中有一个文件可写，`select` 就会返回一个大于 `0` 的值，表示有文件可写；
- `errorfds` 同上面两个参数的意图，用来监视文件错误异常;
- `timeout` 是 `select` 的超时时间，可以使 `select` 处于 `3` 种状态：
  - 若将 NULL 以形参传入，即不传入时间结构，就是将 `select` 置于阻塞状态，等到监视文件描述符集合中某个文件描述符发生变化为止；
  - 若将时间值设为 `0`，就变成一个纯粹的非阻塞函数，不论文件描述符是否有有变化，都立刻返回继续执行，文件无变化返回 `0`，有变化返回一个正值；
  - `timeout` 的值大于 `0`，这就是等待的超时时间，即 `select` 在 `timeout` 时间内阻 ，超时时间之内有事件到来就返回了，否则在超时后不管怎样一定返回，返回值同上述。
- 返回值：准备就绪的描述符数，若超时返回 `0`，出错返回 `-1`。
- `select` 使用 **描述符集**，通常是一个整数数组，其中每个整数中的每一位对应一个描述符。举例来说，假设使用32位整数，那么该整数的第一个元素对应于描述符 `0~31`，第二个整数对应于描述符 `32~63`，以此类推。
- `select` 函数返回后，使用 `FD_ISSET` 宏来测试 `fd_set` 数据类型中的描述符。描述符集内任何与未就绪描述符对应的位返回时均清成0。为此，**每次重新调用 `select` 函数时，都得再次把所有描述符集内所关心的位均置为 1**。

#### select 实现源码

[select实现源码](http://gityuan.com/2019/01/05/linux-poll-select/)

#### select Demo

- 使用 `select` 函数循环读取键盘输入：

``` c++
#include <sys/time.h>  
#include <stdio.h>  
#include <sys/types.h>  
#include <sys/stat.h>  
#include <fcntl.h>  
#include <assert.h>  
#include <stdlib.h>
#include <string.h>
#include <unistd.h>
#include <sys/socket.h>
#include <netinet/in.h>
#include <arpa/inet.h>
#include <errno.h>
#include <sys/select.h>
int main(){
	int keyboard; 
	int ret,i; 
	char c;
	fd_set readfd;
	struct timeval timeout;
	keyboard = open("/dev/tty",O_RDONLY | O_NONBLOCK);		// 非阻塞地读取终端上的输入信息
	assert(keyboard>0);
	while(1) {
		timeout.tv_sec=5;
		timeout.tv_usec=0;
		FD_ZERO(&readfd);
		FD_SET(keyboard,&readfd);
		ret=select(keyboard+1,&readfd,NULL,NULL,&timeout);
		if (ret == -1)
			perror("select error");
		else if (ret){
			if(FD_ISSET(keyboard,&readfd)){
				i=read(keyboard,&c,1);
				if('\n'==c)
					continue;
				printf("The input is %c\n",c);
				if ('q'==c)
					break;
			}  
               }else if (ret == 0)
                   printf("time out\n");
	}
	return 0;
}  
```

- 使用 `select` 函数提高服务器的处理能力，服务端代码：

``` c++
#include <sys/types.h>
#include <sys/socket.h>
#include <netinet/in.h>
#include <arpa/inet.h>
#include <unistd.h>
#include <stdio.h>
#include <stdlib.h>
#include <strings.h>
#include <sys/wait.h>
#include <string.h>
#include <errno.h>
#define DEFAULT_PORT 6666
int main( int argc, char ** argv){
    int serverfd,acceptfd; /* 监听socket: serverfd,数据传输socket: acceptfd */
    struct sockaddr_in my_addr; /* 本机地址信息 */
    struct sockaddr_in their_addr; /* 客户地址信息 */
    unsigned int sin_size, myport=6666, lisnum=10;
    if ((serverfd = socket(AF_INET , SOCK_STREAM, 0)) == -1) {
       perror("socket" );
       return -1;
    }
    printf("socket ok \n");
    my_addr.sin_family=AF_INET;
    my_addr.sin_port=htons(DEFAULT_PORT);
    my_addr.sin_addr.s_addr = INADDR_ANY;
    bzero(&(my_addr.sin_zero), 0);
    if (bind(serverfd, (struct sockaddr *)&my_addr, sizeof(struct sockaddr )) == -1) {
        perror("bind" );
        return -2;
    }
    printf("bind ok \n");
    if (listen(serverfd, lisnum) == -1) {
        perror("listen" );
        return -3;
    }
    printf("listen ok \n");
	
	fd_set client_fdset;	/*监控文件描述符集合*/
	int maxsock;            /*监控文件描述符中最大的文件号*/
	struct timeval tv;		/*超时返回时间*/
	int client_sockfd[5];   /*存放活动的sockfd*/
	bzero((void*)client_sockfd,sizeof(client_sockfd));
	int conn_amount = 0;    /*用来记录描述符数量*/
	maxsock = serverfd;
	char buffer[1024];
	int ret=0;
	while(1){
		/*初始化文件描述符号到集合*/
		FD_ZERO(&client_fdset);
		/*加入服务器描述符*/
		FD_SET(serverfd,&client_fdset);
		/*设置超时时间*/
		tv.tv_sec = 30; /*30秒*/
		tv.tv_usec = 0;
		/*把活动的句柄加入到文件描述符中*/
        for(int i = 0; i < 5; ++i){
            /*程序中Listen中参数设为5,故i必须小于5*/
            if(client_sockfd[i] != 0){
                FD_SET(client_sockfd[i], &client_fdset);
            }
         }
		/*printf("put sockfd in fdset!\n");*/
        /*select函数*/
        ret = select(maxsock+1, &client_fdset, NULL, NULL, &tv);
        if(ret < 0){
            perror("select error!\n");
            break;
        }
        else if(ret == 0){
            printf("timeout!\n");
            continue;
        }
        /*轮询各个文件描述符*/
        for(int i = 0; i < conn_amount; ++i){
            /*FD_ISSET检查client_sockfd是否可读写，>0可读写*/
            if(FD_ISSET(client_sockfd[i], &client_fdset)){
                printf("start recv from client[%d]:\n",i);
                ret = recv(client_sockfd[i], buffer, 1024, 0);
                if(ret <= 0){
                    printf("client[%d] close\n", i);
                    close(client_sockfd[i]);
                    FD_CLR(client_sockfd[i], &client_fdset);
                    client_sockfd[i] = 0;
                }
                else{
                    printf("recv from client[%d] :%s\n", i, buffer);
                }
            }
        }
		/*检查是否有新的连接，如果收，接收连接，加入到client_sockfd中*/
		if(FD_ISSET(serverfd, &client_fdset)){
	    	/*接受连接*/
	    	struct sockaddr_in client_addr;
        	size_t size = sizeof(struct sockaddr_in);
			int sock_client = accept(serverfd, (struct sockaddr*)(&client_addr),                                                                                      (unsigned int*)(&size));
            if(sock_client < 0){
                perror("accept error!\n");
                continue;
            }
			/*把连接加入到文件描述符集合中*/
            if(conn_amount < 5){
                client_sockfd[conn_amount++] = sock_client;
                bzero(buffer,1024);
                strcpy(buffer, "this is server! welcome!\n");
                send(sock_client, buffer, 1024, 0);
                printf("new connection client[%d] %s:%d\n", conn_amount,                                                                                inet_ntoa(client_addr.sin_addr), ntohs(client_addr.sin_port));
                bzero(buffer,sizeof(buffer));
                ret = recv(sock_client, buffer, 1024, 0);
                if(ret < 0){
                    perror("recv error!\n");
                    close(serverfd);
                    return -1;
                }
                printf("recv : %s\n",buffer);
                if(sock_client > maxsock){
                    maxsock = sock_client;
                }
                else{
                    printf("max connections!!!quit!!\n");
                    break;
                }
            }
        }
    }
    for(int i = 0; i < 5; ++i){
        if(client_sockfd[i] != 0){
            close(client_sockfd[i]);
        }
    }
    close(serverfd);
    return 0;	
}

```

- 客户端代码：

``` c++
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <unistd.h>
#include <sys/types.h>
#include <sys/socket.h>
#include <netinet/in.h>
#include <arpa/inet.h>
#include <errno.h>
#define DEFAULT_PORT 6666
int main( int argc, char * argv[]){
    int connfd = 0;
    int cLen = 0;
    struct sockaddr_in client;
    if(argc < 2){
        printf(" Uasge: clientent [server IP address]\n");
        return -1;
    }	
    client.sin_family = AF_INET;
    client.sin_port = htons(DEFAULT_PORT);
    client.sin_addr.s_addr = inet_addr(argv[1]);
    connfd = socket(AF_INET, SOCK_STREAM, 0);
    if(connfd < 0){
	    perror("socket" );
        return -1;
    }
    if(connect(connfd, (struct sockaddr*)&client, sizeof(client)) < 0){
 	    perror("connect" );
        return -1;
    }
	char buffer[1024];
	bzero(buffer,sizeof(buffer));
	recv(connfd, buffer, 1024, 0);
	printf("recv : %s\n", buffer);
	bzero(buffer,sizeof(buffer));
	strcpy(buffer,"this is client!\n");
	send(connfd, buffer, 1024, 0);
	while(1){
		bzero(buffer,sizeof(buffer));
		scanf("%s",buffer);
		int p = strlen(buffer);
		buffer[p] = '\0';
		send(connfd, buffer, 1024, 0);
		printf("i have send buffer\n");
	}
	close(connfd);
	return 0;
}
```

- 如此，server 就能同时处理多个 client 的请求。

### poll 函数

- `poll` 函数原型：

``` c
#include <poll.h>

int poll(struct pollfd *fds, unsigned int nfds, int timeout);

struct pollfd {
    int fd;
    short events;		/* 等待的事件 */
    short revents;		/* 实际发生了的事件 */
};
```

每一个 `poll 结构体` 指定了一个被监视的文件描述符，可以传递多个结构体，指示 `poll()` 监视多个文件描述符。每个结构体的 `events` 域是监视该文件描述符的事件掩码，由用户来设置这个域的属性 `revents` 是文件描述符的操作结果事件掩码，内核在调用返回时设置这个域。成功时，`poll()` 返回结构体中 `revents` 域不为 0 的文件描述符个数：如果在超时前没有任何事件发生，`poll()` 返回 0； 失败时，`poll()` 返回 -1。

| 事件分类 |     事件代码     |           意义           |
| :------: | :--------------: | :----------------------: |
|          |     `POLLIN`     |        有数据可读        |
|          |   `POLLRDNORM`   |      有普通数据可读      |
|          |   `POLLRDBAND`   |      有优先数据可读      |
| 合法事件 |    `POLLPRI`     |      有紧迫数据可读      |
|          |    `POLLOUT`     |    写数据不会导致阻塞    |
|          |   `POLLWRNORM`   |  写普通数据不会导致阻塞  |
|          |   `POLLWRBAND`   |  写优先数据不会导致阻塞  |
|          | `POLLMSGSIGPOLL` |         消息可用         |
|          |     `POLLER`     | 指定的文件描述符发生错误 |
| 非法事件 |    `POLLHUP`     | 指定的文件描述符挂起事件 |
|          |    `POLLNAVL`    |   指定的文件描述符非法   |

- `POLLIN | POLLPRI` 等价于 `select` 的读事件，`POLLOUT | POLLWRBAND` 等价于 `select()` 的写事件
- 使用 `poll` 函数提高服务器的处理能力，服务端实现代码：

```c++
#include <sys/types.h>
#include <sys/socket.h>
#include <netinet/in.h>
#include <arpa/inet.h>
#include <unistd.h>
#include <stdio.h>
#include <stdlib.h>
#include <strings.h>
#include <sys/wait.h>
#include <string.h>
#include <errno.h>
#include <poll.h>
#define IPADDRESS   "127.0.0.1"
#define PORT        6666
#define MAXLINE     1024
#define LISTENQ     5
#define OPEN_MAX    1000
#define INFTIM      -1

/*创建套接字,进行绑定和监听*/
int bind_and_listen(){
	int serverfd; /* 监听socket: serverfd*/
    struct sockaddr_in my_addr; /* 本机地址信息 */
    unsigned int sin_size;
    if ((serverfd = socket(AF_INET , SOCK_STREAM, 0)) == -1) {
       perror("socket" );
       return -1;
    }
    printf("socket ok \n");	
    my_addr.sin_family=AF_INET;
    my_addr.sin_port=htons(PORT);
    my_addr.sin_addr.s_addr = INADDR_ANY;
    bzero(&(my_addr.sin_zero), 0);
    if (bind(serverfd, (struct sockaddr *)&my_addr, sizeof(struct sockaddr )) == -1) {
        perror("bind" );
        return -2;
    }
    printf("bind ok \n");
    if (listen(serverfd, LISTENQ) == -1) {
        perror("listen" );
        return -3;
    }
    printf("listen ok \n");
	return serverfd;
}

/*IO多路复用poll*/
void do_poll(int listenfd){
    int  connfd,sockfd;
    struct sockaddr_in cliaddr;
    socklen_t cliaddrlen;
    struct pollfd clientfds[OPEN_MAX];
    int maxi;
    int i;
    int nready;
    /*添加监听描述符*/
    clientfds[0].fd = listenfd;
    clientfds[0].events = POLLIN;
    /* 初始化客户连接描述符，注意别把第一个元素给覆盖了，因为第一个已添加了服务器描述符*/
    for (i = 1;i < OPEN_MAX;i++)
        clientfds[i].fd = -1;
    maxi = 0;
    
    // 接着是 while 循环，查看是否有新客户端连接，或者老客户端是否有数据发送过来
	// 这里的超时时间设为 -1 ，表示无限超时，使 poll() 一直挂起直到一个指定事件发生
    while(1){
        /*获取可用描述符的个数*/
        nready = poll(clientfds,maxi+1,INFTIM);
        if (nready == -1){
            perror("poll error:");
            exit(1);
        }
        /*测试监听描述符是否准备好*/
        if (clientfds[0].revents & POLLIN){
            cliaddrlen = sizeof(cliaddr);
            /* 接受新的连接 */
       		if((connfd=accept(listenfd,(struct sockaddr*)&cliaddr,&cliaddrlen))==-1){
                if (errno == EINTR)
                    continue;
                else{
                    perror("accept error:");
                    exit(1);
                }
            }
			fprintf(stdout,"accept a new client: %s:%d\n", inet_ntoa(cliaddr.sin_addr), 					cliaddr.sin_port);
       		/*将新的连接描述符添加到数组中*/
            for (i = 1;i < OPEN_MAX;i++){
                if (clientfds[i].fd < 0){
                    clientfds[i].fd = connfd;
                    break;
                }
            }
            if (i == OPEN_MAX){
                fprintf(stderr,"too many clients.\n");
                exit(1);
            }
            /*将新的描述符添加到读描述符集合中*/
            clientfds[i].events = POLLIN;
            /*记录客户连接套接字的个数*/
            maxi = (i > maxi ? i : maxi);
            if (--nready <= 0)
                  continue;
        }
        /*处理多个已有连接上客户端发来的包*/
        char buf[MAXLINE];
        memset(buf,0,MAXLINE);
        int readlen=0;
        for (i = 1; i <= maxi; i++){
            if (clientfds[i].fd < 0)
                continue;
            /*测试客户描述符是否准备好*/
            if (clientfds[i].revents & POLLIN){
                /*接收客户端发送的信息*/
                readlen = read(clientfds[i].fd,buf,MAXLINE);
                if (readlen == 0){
                    close(clientfds[i].fd);
                    clientfds[i].fd = -1;
                    continue;
                }
                /*printf("read msg is: ");*/
                write(STDOUT_FILENO,buf,readlen);
                /*向客户端发送buf*/
                write(clientfds[i].fd,buf,readlen);
            }
        }
    }
}
int main(int argc,char *argv[]){
    int  listenfd=bind_and_listen();
	if(listenfd<0){
	    return 0;
	}
    do_poll(listenfd);
    return 0;
}
```

- 客户端实现代码：

``` c++
#include <sys/types.h>
#include <sys/socket.h>
#include <netinet/in.h>
#include <arpa/inet.h>
#include <unistd.h>
#include <stdio.h>
#include <stdlib.h>
#include <strings.h>
#include <sys/wait.h>
#include <string.h>
#include <errno.h>
#include <poll.h>
#define MAXLINE     1024
#define DEFAULT_PORT   6666
#define max(a,b) (a > b) ? a : b
static void handle_connection(int sockfd);
int main(int argc,char *argv[]){
	int connfd = 0;
    int cLen = 0;
    struct sockaddr_in client;
    if(argc < 2){
        printf(" Uasge: clientent [server IP address]\n");
        return -1;
    }	
    client.sin_family = AF_INET;
    client.sin_port = htons(DEFAULT_PORT);
    client.sin_addr.s_addr = inet_addr(argv[1]);
    connfd = socket(AF_INET, SOCK_STREAM, 0);
    if(connfd < 0){
		perror("socket" );
        return -1;
    }
    if(connect(connfd, (struct sockaddr*)&client, sizeof(client)) < 0){
 		perror("connect" );
        return -1;
    }
    /*处理连接描述符*/
    handle_connection(connfd);
    return 0;
}
static void handle_connection(int sockfd){
    char    sendline[MAXLINE],recvline[MAXLINE];
    int     maxfdp,stdineof;
    struct pollfd pfds[2];
    int n;
    /*添加连接描述符*/
    pfds[0].fd = sockfd;
    pfds[0].events = POLLIN;
    /*添加标准输入描述符*/
    pfds[1].fd = STDIN_FILENO;
    pfds[1].events = POLLIN;
    while(1){
        poll(pfds,2,-1);
        /* 测试服务器是否发来了包 */
        if (pfds[0].revents & POLLIN){
            n = read(sockfd,recvline,MAXLINE);
            if (n == 0){
                    fprintf(stderr,"client: server is closed.\n");
                    close(sockfd);
            }
            write(STDOUT_FILENO,recvline,n);
        }
        /* 测试标准输入是否有输入 */
        if (pfds[1].revents & POLLIN) {
            n = read(STDIN_FILENO,sendline,MAXLINE);
            if (n  == 0) {
                shutdown(sockfd,SHUT_WR);
				continue;
            }
            write(sockfd,sendline,n);
        }
    }
}

```

- `poll` 函数也能让服务器具备同时处理多个客户端请求的能力。

### epoll 函数

- 相对于 `select` 和 `poll` 来说， `epoll` 更加灵活，**没有描述符限制**；
- `epoll` 使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样 **在用户空间和内核空间之间的数据拷贝只需一次**。
- `epoll` 函数接口：

``` c++
#include <sys/epoll.h>

int epoll_create(int size);
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);
int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout);
```

- 三个接口的功能、入参和出参的含义：

  - `epoll_create` 创建一个 `epoll` 句柄，`size` 用来告诉内核要监听的数目。需要注意的是，当创建好 `epoll` 句柄后，它就会占用一个 `fd` 值，在 Linux 下如果查看 /proc/ 进程的 id/fd/ ，是能够看到这个 `fd` 值的，所以在使用 `poll` 后，必须调用 `close()` 关闭，否则可能导致 `fd` 被耗尽；
  - `epoll_ctl` 是 `epoll` 的事件注册函数，它不同于 `select` 在监听事件时告诉内核要监听什么类型的事件，而是先注册要监听的事件类型。第一个参数是 `epoll_create()` 的返回值，第二个参数表示动作，用 3 个宏来表示：① `EPOLL_CTL_ADD`，注册新的 `fd` 到 `epfd` 中；② `EPOLL_CTL_MOD` ，修改已经注册的 `fd` 的监昕事件；③ `EPOLL_ CTL DEL` ：从 `epfd` 中删除一个 `fd`；第 3 个参数是需要监听的 `fd`，第 4 个参数是告诉内核需要监听什么事， `struct epoll_event` 结构如下：

  ``` c++
  struct epoll_event {
      _uint32_t events;
      epoll_data_t data;
  }
  ```

  ​		`events` 包括：`EPOLLIN`、`EPOLLOUT`、`EPOLLPRI`、`EPOLLERR`、`EPOLLHUP`、`EPOLLET`。

  - `epoll_wait` 用来等待事件的发生。

#### epoll 实现原理：

[epoll实现原理](https://blog.csdn.net/Replus_/article/details/96123476)

#### epoll Demo

- 用 `epoll` 提高服务器分处理能力，服务端代码：

``` c++
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <errno.h>

#include <netinet/in.h>
#include <sys/socket.h>
#include <arpa/inet.h>
#include <sys/epoll.h>
#include <unistd.h>
#include <sys/types.h>

#define IPADDRESS   "127.0.0.1"
#define PORT        6666
#define MAXSIZE     1024
#define LISTENQ     5
#define FDSIZE      1000
#define EPOLLEVENTS 100

/*函数声明*/
/*创建套接字并进行绑定*/
int socket_bind(const char* ip,int port);
/*IO多路复用epoll*/
void do_epoll(int listenfd);
/*事件处理函数*/
void handle_events(int epollfd,struct epoll_event *events,int num,int listenfd,char *buf);
/*处理接收到的连接*/
void handle_accpet(int epollfd,int listenfd);
/*读处理*/
void do_read(int epollfd,int fd,char *buf);
/*写处理*/
void do_write(int epollfd,int fd,char *buf);
/*添加事件*/
void add_event(int epollfd,int fd,int state);
/*修改事件*/
void modify_event(int epollfd,int fd,int state);
/*删除事件*/
void delete_event(int epollfd,int fd,int state);

int main(int argc,char *argv[]){
    int  listenfd;
    listenfd = socket_bind(IPADDRESS,PORT);
    listen(listenfd,LISTENQ);
    do_epoll(listenfd);
    return 0;
}

int socket_bind(const char* ip,int port){
    int  listenfd;
    struct sockaddr_in servaddr;
    listenfd = socket(AF_INET,SOCK_STREAM,0);
    if (listenfd == -1){
        perror("socket error:");
        exit(1);
    }
    bzero(&servaddr,sizeof(servaddr));
    servaddr.sin_family = AF_INET;
    inet_pton(AF_INET,ip,&servaddr.sin_addr);
    servaddr.sin_port = htons(port);
    if (bind(listenfd,(struct sockaddr*)&servaddr,sizeof(servaddr)) == -1){
        perror("bind error: ");
        exit(1);
    }
    return listenfd;
}

void do_epoll(int listenfd){
    int epollfd;
    struct epoll_event events[EPOLLEVENTS];
    int ret;
    char buf[MAXSIZE];
    memset(buf,0,MAXSIZE);
    /*创建一个描述符*/
    epollfd = epoll_create(FDSIZE);
    /*添加监听描述符事件*/
    add_event(epollfd,listenfd,EPOLLIN);
    while(1){
        /*获取已经准备好的描述符事件*/
        ret = epoll_wait(epollfd,events,EPOLLEVENTS,-1);
        handle_events(epollfd,events,ret,listenfd,buf);
    }
    close(epollfd);
}

void handle_events(int epollfd,struct epoll_event *events,int num,int listenfd,char *buf){
    int i;
    int fd;
    /*进行遍历*/
    for (i = 0;i < num;i++){
        fd = events[i].data.fd;
        /*根据描述符的类型和事件类型进行处理*/
        if ((fd == listenfd) &&(events[i].events & EPOLLIN))
            handle_accpet(epollfd,listenfd);
        else if (events[i].events & EPOLLIN)
            do_read(epollfd,fd,buf);
        else if (events[i].events & EPOLLOUT)
            do_write(epollfd,fd,buf);
    }
}

void handle_accpet(int epollfd,int listenfd){
    int clifd;
    struct sockaddr_in cliaddr;
    socklen_t  cliaddrlen;
    clifd = accept(listenfd,(struct sockaddr*)&cliaddr,&cliaddrlen);
    if (clifd == -1)
        perror("accpet error:");
    else{
        printf("accept a new client:                                                                     %s:%d\n",inet_ntoa(cliaddr.sin_addr),cliaddr.sin_port);
        /*添加一个客户描述符和事件*/
        add_event(epollfd,clifd,EPOLLIN);
    }
}

void do_read(int epollfd,int fd,char *buf){
    int nread;
    nread = read(fd,buf,MAXSIZE);
    if (nread == -1){
        perror("read error:");
        close(fd);
        delete_event(epollfd,fd,EPOLLIN);
    }
    else if (nread == 0){
        fprintf(stderr,"client close.\n");
        close(fd);
        delete_event(epollfd,fd,EPOLLIN);
    }
    else{
        printf("read message is : %s",buf);
        /*修改描述符对应的事件，由读改为写*/
        modify_event(epollfd,fd,EPOLLOUT);
    }
}

void do_write(int epollfd,int fd,char *buf){
    int nwrite;
    nwrite = write(fd,buf,strlen(buf));
    if (nwrite == -1){
        perror("write error:");
        close(fd);
        delete_event(epollfd,fd,EPOLLOUT);
    }
    else
        modify_event(epollfd,fd,EPOLLIN);
    memset(buf,0,MAXSIZE);
}

void add_event(int epollfd,int fd,int state){
    struct epoll_event ev;
    ev.events = state;
    ev.data.fd = fd;
    epoll_ctl(epollfd,EPOLL_CTL_ADD,fd,&ev);
}

void delete_event(int epollfd,int fd,int state){
    struct epoll_event ev;
    ev.events = state;
    ev.data.fd = fd;
    epoll_ctl(epollfd,EPOLL_CTL_DEL,fd,&ev);
}

void modify_event(int epollfd,int fd,int state){
    struct epoll_event ev;
    ev.events = state;
    ev.data.fd = fd;
    epoll_ctl(epollfd,EPOLL_CTL_MOD,fd,&ev);
}
```

- 客户端代码：

``` c++
#include <netinet/in.h>
#include <sys/socket.h>
#include <stdio.h>
#include <string.h>
#include <stdlib.h>
#include <sys/epoll.h>
#include <time.h>
#include <unistd.h>
#include <sys/types.h>
#include <arpa/inet.h>

#define MAXSIZE     1024
#define IPADDRESS   "127.0.0.1"
#define SERV_PORT   6666
#define FDSIZE        1024
#define EPOLLEVENTS 20

void handle_connection(int sockfd);
void handle_events(int epollfd,struct epoll_event *events,int num,int sockfd,char *buf);
void do_read(int epollfd,int fd,int sockfd,char *buf);
void do_read(int epollfd,int fd,int sockfd,char *buf);
void do_write(int epollfd,int fd,int sockfd,char *buf);
void add_event(int epollfd,int fd,int state);
void delete_event(int epollfd,int fd,int state);
void modify_event(int epollfd,int fd,int state);
int count=0;
int main(int argc,char *argv[]){
    int                 sockfd;
    struct sockaddr_in  servaddr;
    sockfd = socket(AF_INET,SOCK_STREAM,0);
    bzero(&servaddr,sizeof(servaddr));
    servaddr.sin_family = AF_INET;
    servaddr.sin_port = htons(SERV_PORT);
    inet_pton(AF_INET,IPADDRESS,&servaddr.sin_addr);
    connect(sockfd,(struct sockaddr*)&servaddr,sizeof(servaddr));
    /*处理连接*/
    handle_connection(sockfd);
    close(sockfd);
    return 0;
}

void handle_connection(int sockfd){
    int epollfd;
    struct epoll_event events[EPOLLEVENTS];
    char buf[MAXSIZE];
    int ret;
    epollfd = epoll_create(FDSIZE);
    add_event(epollfd,STDIN_FILENO,EPOLLIN);
    while (1 ) {
        ret = epoll_wait(epollfd,events,EPOLLEVENTS,-1);
        handle_events(epollfd,events,ret,sockfd,buf);
    }
    close(epollfd);
}

void handle_events(int epollfd,struct epoll_event *events,int num,int sockfd,char *buf){
    int fd;
    int i;
    for (i = 0;i < num;i++){
        fd = events[i].data.fd;
        /* 客户端需要关注三种状态：标准输入、服务器发来了数据、标准输出*/
        if (events[i].events & EPOLLIN)				// 标准输入或服务器发来了数据
            do_read(epollfd,fd,sockfd,buf);
        else if (events[i].events & EPOLLOUT)		// 标准输出
            do_write(epollfd,fd,sockfd,buf);
    }
}

void do_read(int epollfd,int fd,int sockfd,char *buf){
    int nread;
    nread = read(fd,buf,MAXSIZE);
    if (nread == -1){
        perror("read error:");
        close(fd);
    }
    else if (nread == 0){
        fprintf(stderr,"server close.\n");
        close(fd);
    }
    else{
        // 标准输入
        if (fd == STDIN_FILENO)
            add_event(epollfd,sockfd,EPOLLOUT);
        else{	// 服务器发来了消息
            delete_event(epollfd,sockfd,EPOLLIN);
            add_event(epollfd,STDOUT_FILENO,EPOLLOUT);
        }
    }
}

void do_write(int epollfd,int fd,int sockfd,char *buf){
    int nwrite;
    char temp[100];
	buf[strlen(buf)-1]='\0';
	snprintf(temp,sizeof(temp),"%s_%02d\n",buf,count++);
    nwrite = write(fd,temp,strlen(temp));   
    if (nwrite == -1){
        perror("write error:");
        close(fd);
    }
    else{
        if (fd == STDOUT_FILENO)
            delete_event(epollfd,fd,EPOLLOUT);
        else
            modify_event(epollfd,fd,EPOLLIN);
    }
    memset(buf,0,MAXSIZE);
}

void add_event(int epollfd,int fd,int state){
    struct epoll_event ev;
    ev.events = state;
    ev.data.fd = fd;
    epoll_ctl(epollfd,EPOLL_CTL_ADD,fd,&ev);
}

void delete_event(int epollfd,int fd,int state){
    struct epoll_event ev;
    ev.events = state;
    ev.data.fd = fd;
    epoll_ctl(epollfd,EPOLL_CTL_DEL,fd,&ev);
}

void modify_event(int epollfd,int fd,int state){
    struct epoll_event ev;
    ev.events = state;
    ev.data.fd = fd;
    epoll_ctl(epollfd,EPOLL_CTL_MOD,fd,&ev);
}
```



### 描述符就绪条件

#### 套接字准备好读

- 该套接字接收缓冲区中的数据字节数大于等于套接字接收缓冲区 **低水位标记** 的当前大小
- 该连接的读半部关闭（也就是接收了 FIN 的TCP 连接），对这样的套接字的读操作将不阻塞并返回 0；
- 该套接字是一个监听套接字且已完成的连接数不为 0；
- 其上有一个套接字错误待处理；

#### 套接字准备好写

- 该套接字发送缓冲区中的可用空间字节数大于等于套接字发送缓冲区 **低水位标记** 的当前大小，并且或者该套接字已连接，或者该套接字不需要连接（UDP套接字）；
- 该连接的写半部关闭，对这样的套接字的写操作将产生 `SIGPIPE 信号`。

接收低水位标记和发送高水位标记的目的在于：**允许应用进程控制在 `select` 返回可读或可写条件之前有多少数据可读或有多大空间可用于写**。举例来说：如果我们知道除非至少存在 64 个字节的数据，否则应用进程没有任何有效工作可做，那么就可以把接收低水位标记设置为 64。

### select、poll、epoll 的区别

- `select`、`poll` 和 `epoll` 都是 **多路 IO 复用** 的机制；多路 IO 复用就通过这种机制，可以监视多个描述符， 一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作；
- `select`、`poll` 和 `epoll` 本质上都是 **同步 IO**，因为它们都需要在读写事件就绪后自己负责进行读写，即是**阻塞的**，而异步 IO 则无须自己负责读写，异步 IO 的实现会把数据从内核拷贝到用户空间；
- `select` 和 `poll`：
  - 一般认为 `poll()` 比 `select()` 要高级一些；
  - `poll()` 不要求开发者在计算最大文件描述符时进行 +1 的操作；
  - `poll()` 在应付大数目的文件描述符的时候速度更快，因为对于 `select()` 来说 **内核需要检查大量描述符对应的 `fd_set` 中的每一个比特位，比较费时**；
  - `select()`）可以监控的文件描述符数目是固定的，相对来说也较少 (1024或2048)。如果需要监控数值比较大的文件描述符，或是 **分布得很稀疏的较少的描述符**，效率也会很低。而对于 `poll()` 函数来说，可以创建特定大小的数组来保存监控的描述符，而不受文件描述符值大小的影响，而且 `poll()` 可以监控的文件数远大于 `select()`；
  - 对于 `select()` 来说，所监控的 `fd_set` 在 `select()` 返回之后会发生变化，所以在下一次进入 `select()` 之前都需要重新初始化需要监控的 `fd_set`；`poll()` 函数将监控的输入 `events` 和输出事件 `revents` 分开，允许被监控的文件数组被复用而不需要重新初始化；
  - `select()` 函数的超时参数在返回时也是未定义的，考虑到可移植性，每次在超时之后在下一次进入到 `select()` 之前都需要重新设置超时参数。
- `epoll()` 的优点：
  - 支持一个进程打开大数目的描述符；
  
  - IO 效率不随描述符数目增加而线性下降；`select/poll` 每次调用都会 **线性扫描全部的描述符**，导致效率呈现线性下降，但是 `epoll` 不存在这个问题，它只会对“活跃”的 `socket` 进行操作，这是因为在内核中实现 `poll` 是根据每个描述符 `fd` 上面的 `callback` 函数实现的。那么，只有“活跃”的 `socket` 才会主动去调用 `callback` 函数，其他 `idle` 状态的 socket 则不会。
  
  - 使用 `mmap` 加速内核与用户空间的消息传递。无论是 `select`、`poll` 还是 `epoll` 需要内核把 `fd` 消息通知给用户空间，如何避免不必要的内存拷贝就显得尤为重要。在这点上，**`epoll` 是通过内核与用户空间 `mmap` 处于同一块内存实现的**。
  
    对于 `poll` 来说需要将用户传入的 `pollfd` 数组拷贝到内核空间，因为拷贝操作和数组长度相关，时间上来看，这是 $O(n)$ 操作，当事件发生后，`poll` 将获得的数据传送到用户空间，并执行释放内存和剥离等待队列等工作，向用户空间拷贝数据与剥离等待队列等操作的时间复杂度同样是 $O(n)$
  
  - `epoll` 有 **EPOLLLT** 和 **EPOLLET** 两种触发模式，LT 是默认的模式，ET 是“高速”模式
  
    - LT 模式下，只要这个 `fd` 还有数据可读，每次 `epoll_wait` 都会返回它的事件，提醒用户程序去操作；
    - ET（边缘触发）模式中，它只会提示一次，直到下次再有数据流入之前都不会再提示了，无论 `fd` 中是否还有数据可读。所以在 ET 模式下，读一个 `fd` 的时候一定要把它的 buffer 读光，也就是说一直读到 read 的返回值小于请求值;
    - 如果采用 LT 模式的话，系统中一旦有大量你不需要读写的就绪文件描述符，它们每次调 `epoll_wait` 都会返回，这样会大大降低处理程序检索自己关心的就绪文件描述符的效率；而 ET 模式下，系统不会充斥大量你不关心的就绪文件描述符；

### epoll 各类问题链接

[epoll 类问题](https://zhuanlan.zhihu.com/p/378176093)

